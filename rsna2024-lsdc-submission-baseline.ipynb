{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57590094",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.008575,
     "end_time": "2024-10-03T05:02:01.398639",
     "exception": false,
     "start_time": "2024-10-03T05:02:01.390064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adopted from https://www.kaggle.com/code/yxyyxy/rsna2024-training-baseline-2nd-stage/edit\n",
    "\n",
    "# RSNA2024 LSDC Submission Baseline\n",
    "\n",
    "This notebook will Let the model infer and make a submission.\n",
    "\n",
    "### My other Notebooks\n",
    "- [RSNA2024 LSDC Making Dataset](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-making-dataset) \n",
    "- [RSNA2024 LSDC Training Baseline](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-training-baseline) \n",
    "- [RSNA2024 LSDC Submission Baseline](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline) <- you're reading now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba38396",
   "metadata": {
    "papermill": {
     "duration": 0.007609,
     "end_time": "2024-10-03T05:02:01.414212",
     "exception": false,
     "start_time": "2024-10-03T05:02:01.406603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54dc7e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:01.431156Z",
     "iopub.status.busy": "2024-10-03T05:02:01.430817Z",
     "iopub.status.idle": "2024-10-03T05:02:01.442128Z",
     "shell.execute_reply": "2024-10-03T05:02:01.441304Z"
    },
    "papermill": {
     "duration": 0.022239,
     "end_time": "2024-10-03T05:02:01.444136",
     "exception": false,
     "start_time": "2024-10-03T05:02:01.421897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "if DEBUG == True:\n",
    "    rd = '/kaggle/input/rsna-lsdc-2024-submission-debug-dataset/debug'\n",
    "else:\n",
    "    rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "    \n",
    "# Define the directory path\n",
    "DATA_fromStage1 = '/kaggle/working'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85599363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:01.461500Z",
     "iopub.status.busy": "2024-10-03T05:02:01.460685Z",
     "iopub.status.idle": "2024-10-03T05:02:22.527525Z",
     "shell.execute_reply": "2024-10-03T05:02:22.526607Z"
    },
    "papermill": {
     "duration": 21.077867,
     "end_time": "2024-10-03T05:02:22.529789",
     "exception": false,
     "start_time": "2024-10-03T05:02:01.451922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using path: /kaggle/input/2d-segmentation-of-sagittal-lumbar-spine-mri/simple_unet.pth\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\r\n",
      "  warnings.warn(msg)\r\n",
      "Using path: /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\r\n",
      "Using base path: /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images\r\n",
      "Processing studies: 100%|█████████████████████████| 1/1 [00:08<00:00,  8.04s/it]\r\n",
      "Pipeline completed successfully!\r\n",
      "Processing studies: 100%|█████████████████████████| 1/1 [00:00<00:00,  1.14it/s]\r\n",
      "Axial dataset generation completed successfully!\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/input/script-deepspine-custom-dataset/main.py \\\n",
    "\"{rd}/test_series_descriptions.csv\" \\\n",
    "\"{rd}/sample_submission.csv\" \\\n",
    "\"{rd}/test_images\" \\\n",
    "'/kaggle/input/2d-segmentation-of-sagittal-lumbar-spine-mri/simple_unet.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814ee9f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:22.550567Z",
     "iopub.status.busy": "2024-10-03T05:02:22.550263Z",
     "iopub.status.idle": "2024-10-03T05:02:27.601138Z",
     "shell.execute_reply": "2024-10-03T05:02:27.600196Z"
    },
    "papermill": {
     "duration": 5.063004,
     "end_time": "2024-10-03T05:02:27.603601",
     "exception": false,
     "start_time": "2024-10-03T05:02:22.540597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import timm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b2846a",
   "metadata": {
    "papermill": {
     "duration": 0.008221,
     "end_time": "2024-10-03T05:02:27.620652",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.612431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd49450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:27.639723Z",
     "iopub.status.busy": "2024-10-03T05:02:27.639235Z",
     "iopub.status.idle": "2024-10-03T05:02:27.706255Z",
     "shell.execute_reply": "2024-10-03T05:02:27.705391Z"
    },
    "papermill": {
     "duration": 0.079041,
     "end_time": "2024-10-03T05:02:27.708325",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.629284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "N_WORKERS = os.cpu_count()\n",
    "USE_AMP = True\n",
    "SEED = 1\n",
    "\n",
    "IMG_SIZE = [224, 224]\n",
    "N_LABELS = 5\n",
    "N_CLASSES = 3 * N_LABELS\n",
    "\n",
    "model_name_sag = 'efficientnet_b0'\n",
    "model_name_axi = 'resnet34'\n",
    "# resnet34\n",
    "in_chans_sag = 30\n",
    "in_chans_axi = 4\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf49e05c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:27.727036Z",
     "iopub.status.busy": "2024-10-03T05:02:27.726722Z",
     "iopub.status.idle": "2024-10-03T05:02:27.733431Z",
     "shell.execute_reply": "2024-10-03T05:02:27.732605Z"
    },
    "papermill": {
     "duration": 0.018244,
     "end_time": "2024-10-03T05:02:27.735377",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.717133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06810537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:27.753575Z",
     "iopub.status.busy": "2024-10-03T05:02:27.753324Z",
     "iopub.status.idle": "2024-10-03T05:02:27.757900Z",
     "shell.execute_reply": "2024-10-03T05:02:27.757075Z"
    },
    "papermill": {
     "duration": 0.015766,
     "end_time": "2024-10-03T05:02:27.759703",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.743937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "\n",
    "# Define the mapping for each level\n",
    "level_mapping = {\n",
    "    'L1/L2': 'l1_l2',\n",
    "    'L2/L3': 'l2_l3',\n",
    "    'L3/L4': 'l3_l4',\n",
    "    'L4/L5': 'l4_l5',\n",
    "    'L5/S1': 'l5_s1'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fcf302e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:27.777583Z",
     "iopub.status.busy": "2024-10-03T05:02:27.777334Z",
     "iopub.status.idle": "2024-10-03T05:02:27.781778Z",
     "shell.execute_reply": "2024-10-03T05:02:27.780971Z"
    },
    "papermill": {
     "duration": 0.015516,
     "end_time": "2024-10-03T05:02:27.783606",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.768090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78093603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:27.801940Z",
     "iopub.status.busy": "2024-10-03T05:02:27.801702Z",
     "iopub.status.idle": "2024-10-03T05:02:27.820773Z",
     "shell.execute_reply": "2024-10-03T05:02:27.819774Z"
    },
    "papermill": {
     "duration": 0.030337,
     "end_time": "2024-10-03T05:02:27.822750",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.792413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L4/L5</th>\n",
       "      <th>L3/L4</th>\n",
       "      <th>L2/L3</th>\n",
       "      <th>L1/L2</th>\n",
       "      <th>L5/S1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>st_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44036939</th>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L4_L5.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L3_L4.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L2_L3.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L1_L2.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L5_S1.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  L4/L5  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L4_L5.npy   \n",
       "\n",
       "                                                  L3/L4  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L3_L4.npy   \n",
       "\n",
       "                                                  L2/L3  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L2_L3.npy   \n",
       "\n",
       "                                                  L1/L2  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L1_L2.npy   \n",
       "\n",
       "                                                  L5/S1  \n",
       "st_id                                                    \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L5_S1.npy  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to CSV file\n",
    "csv_file_path = DATA_fromStage1 + '/sagittalT2/dataset_metadata.csv'\n",
    "# Read the CSV file\n",
    "dataset_metadata = pd.read_csv(csv_file_path)\n",
    "dataset_metadata.rename(columns={'Unnamed: 0': 'st_id'}, inplace=True)\n",
    "dataset_metadata.set_index('st_id', inplace=True)\n",
    "\n",
    "# # Print the number of columns and rows in the DataFrame\n",
    "# num_rows = dataset_metadata.shape[0]\n",
    "# print(f\"columns: {dataset_metadata.columns}\")\n",
    "# print(f\"Number of rows: {num_rows}\")\n",
    "\n",
    "# # print(dataset_metadata.head())\n",
    "# # Stack the 2nd to 6th columns into a single column\n",
    "# stacked_df = dataset_metadata.stack(dropna=False).reset_index(level=1)\n",
    "# stacked_df.columns = ['Level', 'fn']\n",
    "'''# stacked_df = stacked_df.reset_index(drop=True)\n",
    "print(stacked_df)\n",
    "\n",
    "print(\"----------- test index 0 -------------\")\n",
    "st_id = stacked_df.index[0]\n",
    "row_idx = stacked_df.iloc[0]\n",
    "print(st_id)\n",
    "print(row_idx['Level'])\n",
    "print(row_idx['fn'])\n",
    "print(\"----------- test index 1 -------------\")\n",
    "st_id = stacked_df.index[1]\n",
    "row_idx = stacked_df.iloc[1]\n",
    "print(st_id)\n",
    "print(row_idx['Level'])\n",
    "print(row_idx['fn'])'''\n",
    "\n",
    "dataset_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c712a694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:27.841742Z",
     "iopub.status.busy": "2024-10-03T05:02:27.841073Z",
     "iopub.status.idle": "2024-10-03T05:02:27.848181Z",
     "shell.execute_reply": "2024-10-03T05:02:27.847425Z"
    },
    "papermill": {
     "duration": 0.018396,
     "end_time": "2024-10-03T05:02:27.850071",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.831675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# one npy file example\\nprint(\"--------------------- SagittalT2 samples -----------\")\\nexample_npy_fn = dataset_metadata[\\'L4/L5\\'][0]\\nexample_npy_fn = example_npy_fn.split(\\'/\\')\\n# Load the .npy file\\nexample_npy = np.load(os.path.join(DATA_fromStage1, *(example_npy_fn[-3:])))\\n# Print the structure of the data\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\n# Show the 15 slices one by one\\nfor i in range(15):\\n    plt.imshow(example_npy[i], cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n\\nprint(\"--------------------- SagittalT1 samples -----------\")\\nexample_npy = np.load(os.path.join(DATA_fromStage1, \\'sagittalT1\\', *(example_npy_fn[-2:])))\\n# Print the structure of the data\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\n# Show the 15 slices one by one\\nfor i in range(15):\\n    plt.imshow(example_npy[i], cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n\\nprint(\"--------------------- AxialT2 samples ----------\")\\n# Load the .npy file\\nexample_npy = np.load(os.path.join(DATA_fromStage1, \\'axialT2\\', *(example_npy_fn[-2:])))\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\nfor i in range(6):\\n    img = example_npy[i]\\n    plt.imshow(img, cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# one npy file example\n",
    "print(\"--------------------- SagittalT2 samples -----------\")\n",
    "example_npy_fn = dataset_metadata['L4/L5'][0]\n",
    "example_npy_fn = example_npy_fn.split('/')\n",
    "# Load the .npy file\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, *(example_npy_fn[-3:])))\n",
    "# Print the structure of the data\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "# Show the 15 slices one by one\n",
    "for i in range(15):\n",
    "    plt.imshow(example_npy[i], cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"--------------------- SagittalT1 samples -----------\")\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, 'sagittalT1', *(example_npy_fn[-2:])))\n",
    "# Print the structure of the data\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "# Show the 15 slices one by one\n",
    "for i in range(15):\n",
    "    plt.imshow(example_npy[i], cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"--------------------- AxialT2 samples ----------\")\n",
    "# Load the .npy file\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, 'axialT2', *(example_npy_fn[-2:])))\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "for i in range(6):\n",
    "    img = example_npy[i]\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af353c8",
   "metadata": {
    "papermill": {
     "duration": 0.008888,
     "end_time": "2024-10-03T05:02:27.867871",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.858983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a3e5b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:27.886969Z",
     "iopub.status.busy": "2024-10-03T05:02:27.886713Z",
     "iopub.status.idle": "2024-10-03T05:02:27.905867Z",
     "shell.execute_reply": "2024-10-03T05:02:27.905036Z"
    },
    "papermill": {
     "duration": 0.030901,
     "end_time": "2024-10-03T05:02:27.907777",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.876876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RSNA24TestDataset(Dataset):\n",
    "    def __init__(self, df_fn, Slice_len_Sag=15, Slice_len_Axi=4, transform=None, trainsform_axis=None):\n",
    "        self.df_fn = df_fn\n",
    "        self.transform = transform\n",
    "        self.trainsform_axis = trainsform_axis\n",
    "        self.Slice_len_Sag = Slice_len_Sag\n",
    "        self.Slice_len_Axi = Slice_len_Axi\n",
    "        # Select all rows where the 'Name' column has the value 'Alice'\n",
    "    def __len__(self):\n",
    "        return len(self.df_fn)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        st_id = self.df_fn.index[idx]\n",
    "        row_idx = self.df_fn.iloc[idx]\n",
    "        levels = ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']\n",
    "        filenames = [row_idx[level] for level in levels]\n",
    "        \n",
    "        npy_sagT2_list = []\n",
    "        npy_sagT1_list = []\n",
    "        npy_AxiT2_list = []\n",
    "    \n",
    "        for filename in filenames:\n",
    "            path_split = filename.split('/')\n",
    "            \n",
    "            # Saggital T2 ------------  Load the .npy file\n",
    "            npy_sagT2_path = os.path.join(DATA_fromStage1, path_split[3], path_split[4], path_split[5])\n",
    "            npy_sagT2 = np.load(npy_sagT2_path).astype(np.float32)\n",
    "            current_length = npy_sagT2.shape[0]\n",
    "            if current_length > self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT2 = npy_sagT2[indices, :, :]\n",
    "            elif current_length < self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT2 = npy_sagT2[indices, :, :]\n",
    "            npy_sagT2_list.append(npy_sagT2)\n",
    "            # Saggital T1 ------------  Load the .npy file\n",
    "            npy_sagT1_path = os.path.join(DATA_fromStage1, \"sagittalT1\", path_split[4], path_split[5])\n",
    "            npy_sagT1 = np.load(npy_sagT1_path).astype(np.float32)\n",
    "            current_length = npy_sagT1.shape[0]\n",
    "            if current_length > self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT1 = npy_sagT1[indices, :, :]\n",
    "            elif current_length < self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT1 = npy_sagT1[indices, :, :]\n",
    "            npy_sagT1_list.append(npy_sagT1)\n",
    "            # Axial T2 ------------ Load the .npy file\n",
    "            npy_AxiT2_path = os.path.join(DATA_fromStage1 , \"axialT2\", path_split[4], path_split[5])\n",
    "            npy_AxiT2 = np.load(npy_AxiT2_path).astype(np.float32)\n",
    "            current_length = npy_AxiT2.shape[0]\n",
    "            if current_length > self.Slice_len_Axi:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Axi, dtype=int)\n",
    "                npy_AxiT2 = npy_AxiT2[indices, :, :]\n",
    "            elif current_length < self.Slice_len_Axi:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Axi, dtype=int)\n",
    "                npy_AxiT2 = npy_AxiT2[indices, :, :]\n",
    "            npy_AxiT2_list.append(npy_AxiT2)\n",
    "            \n",
    "        # Transpose and transform the data\n",
    "        npy_sagT1_list = [np.transpose(npy, (1, 2, 0)) for npy in npy_sagT1_list]\n",
    "        npy_sagT2_list = [np.transpose(npy, (1, 2, 0)) for npy in npy_sagT2_list]\n",
    "        npy_AxiT2_list = [np.transpose(npy, (1, 2, 0)) for npy in npy_AxiT2_list]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            npy_sagT1_list = [self.transform(image=npy)['image'] for npy in npy_sagT1_list]\n",
    "            npy_sagT2_list = [self.transform(image=npy)['image'] for npy in npy_sagT2_list]\n",
    "            npy_AxiT2_list = [self.trainsform_axis(image=npy)['image'] for npy in npy_AxiT2_list]\n",
    "\n",
    "        # Transpose back to the original format\n",
    "        npy_sagT1_list = [np.transpose(npy, (2, 0, 1)) for npy in npy_sagT1_list]\n",
    "        npy_sagT2_list = [np.transpose(npy, (2, 0, 1)) for npy in npy_sagT2_list]\n",
    "        npy_AxiT2_list = [np.transpose(npy, (2, 0, 1)) for npy in npy_AxiT2_list]\n",
    "\n",
    "        return st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d96da93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:27.926139Z",
     "iopub.status.busy": "2024-10-03T05:02:27.925901Z",
     "iopub.status.idle": "2024-10-03T05:02:27.930859Z",
     "shell.execute_reply": "2024-10-03T05:02:27.930090Z"
    },
    "papermill": {
     "duration": 0.016124,
     "end_time": "2024-10-03T05:02:27.932665",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.916541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms_test_Sag = A.Compose([\n",
    "    A.Resize(84, 160),\n",
    "    A.Normalize(mean=0.5, std=0.5)\n",
    "])\n",
    "\n",
    "transforms_test = A.Compose([\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "    A.Normalize(mean=0.5, std=0.5)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76702850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:27.951095Z",
     "iopub.status.busy": "2024-10-03T05:02:27.950845Z",
     "iopub.status.idle": "2024-10-03T05:02:27.955464Z",
     "shell.execute_reply": "2024-10-03T05:02:27.954576Z"
    },
    "papermill": {
     "duration": 0.016053,
     "end_time": "2024-10-03T05:02:27.957352",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.941299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = RSNA24TestDataset(dataset_metadata, transform=transforms_test_Sag, trainsform_axis=transforms_test)\n",
    "test_dl = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=1, \n",
    "    shuffle=False,\n",
    "    num_workers=N_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "447296e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:27.975779Z",
     "iopub.status.busy": "2024-10-03T05:02:27.975522Z",
     "iopub.status.idle": "2024-10-03T05:02:27.981569Z",
     "shell.execute_reply": "2024-10-03T05:02:27.980815Z"
    },
    "papermill": {
     "duration": 0.017495,
     "end_time": "2024-10-03T05:02:27.983511",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.966016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from collections import Counter\\n\\nsagT2_slicenum = []\\nAxiT2_slicenum = []\\n\\nprint(test_dl.__len__())\\n\\n# Iterate through the data loader and append slice numbers\\nfor idx, (st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels) in enumerate(test_dl):\\n    for npy_sagT2 in npy_sagT2_list:\\n        sagT2_slicenum.append(npy_sagT2.shape)\\n        assert not torch.isnan(npy_sagT2).any(), \"NaN values found in npy_sagT2\"\\n    \\n    for npy_AxiT2 in npy_AxiT2_list:\\n        AxiT2_slicenum.append(npy_AxiT2.shape)\\n        assert not torch.isnan(npy_AxiT2).any(), \"NaN values found in npy_AxiT2\"\\n    \\n    print(f\"Batch {idx + 1}: Levels - {levels}\")\\n\\n# Count the occurrences of each unique value in the lists\\nsagT2_counts = Counter(sagT2_slicenum)\\nAxiT2_counts = Counter(AxiT2_slicenum)\\n\\nprint(\"Occurrences of each unique value in sagT2_slicenum:\")\\nfor value, count in sagT2_counts.items():\\n    print(f\"Value: {value}, Count: {count}\")\\n\\nprint(\"Occurrences of each unique value in AxiT2_slicenum:\")\\nfor value, count in AxiT2_counts.items():\\n    print(f\"Value: {value}, Count: {count}\")'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from collections import Counter\n",
    "\n",
    "sagT2_slicenum = []\n",
    "AxiT2_slicenum = []\n",
    "\n",
    "print(test_dl.__len__())\n",
    "\n",
    "# Iterate through the data loader and append slice numbers\n",
    "for idx, (st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels) in enumerate(test_dl):\n",
    "    for npy_sagT2 in npy_sagT2_list:\n",
    "        sagT2_slicenum.append(npy_sagT2.shape)\n",
    "        assert not torch.isnan(npy_sagT2).any(), \"NaN values found in npy_sagT2\"\n",
    "    \n",
    "    for npy_AxiT2 in npy_AxiT2_list:\n",
    "        AxiT2_slicenum.append(npy_AxiT2.shape)\n",
    "        assert not torch.isnan(npy_AxiT2).any(), \"NaN values found in npy_AxiT2\"\n",
    "    \n",
    "    print(f\"Batch {idx + 1}: Levels - {levels}\")\n",
    "\n",
    "# Count the occurrences of each unique value in the lists\n",
    "sagT2_counts = Counter(sagT2_slicenum)\n",
    "AxiT2_counts = Counter(AxiT2_slicenum)\n",
    "\n",
    "print(\"Occurrences of each unique value in sagT2_slicenum:\")\n",
    "for value, count in sagT2_counts.items():\n",
    "    print(f\"Value: {value}, Count: {count}\")\n",
    "\n",
    "print(\"Occurrences of each unique value in AxiT2_slicenum:\")\n",
    "for value, count in AxiT2_counts.items():\n",
    "    print(f\"Value: {value}, Count: {count}\")'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38de14af",
   "metadata": {
    "papermill": {
     "duration": 0.008682,
     "end_time": "2024-10-03T05:02:28.001123",
     "exception": false,
     "start_time": "2024-10-03T05:02:27.992441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db0d2293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:28.020154Z",
     "iopub.status.busy": "2024-10-03T05:02:28.019913Z",
     "iopub.status.idle": "2024-10-03T05:02:28.032886Z",
     "shell.execute_reply": "2024-10-03T05:02:28.032094Z"
    },
    "papermill": {
     "duration": 0.024714,
     "end_time": "2024-10-03T05:02:28.034818",
     "exception": false,
     "start_time": "2024-10-03T05:02:28.010104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LevelHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LevelHead, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class RSNA24Model_Hybrid(nn.Module):\n",
    "    def __init__(self, model_name_sag, model_name_axi, in_chans_sag, in_chans_axi, num_classes, level_names):\n",
    "        super(RSNA24Model_Hybrid, self).__init__()\n",
    "        self.model_sag = timm.create_model(model_name_sag, in_chans=in_chans_sag, global_pool='avg'\n",
    "                                           , pretrained=False, features_only=False)\n",
    "        self.model_axi = timm.create_model(model_name_axi, in_chans=in_chans_axi, global_pool='avg'\n",
    "                                           , pretrained=False, features_only=False)\n",
    "        \n",
    "        # Replace the last layer with an identity layer\n",
    "        if hasattr(self.model_sag, 'classifier'):\n",
    "            self.model_sag.classifier = nn.Identity()\n",
    "        elif hasattr(self.model_sag, 'fc'):\n",
    "            self.model_sag.fc = nn.Identity()\n",
    "        \n",
    "        if hasattr(self.model_axi, 'classifier'):\n",
    "            self.model_axi.classifier = nn.Identity()\n",
    "        elif hasattr(self.model_axi, 'fc'):\n",
    "            self.model_axi.fc = nn.Identity()\n",
    "        \n",
    "        # Get the output feature sizes\n",
    "        with torch.no_grad():\n",
    "            sample_input_sag = torch.randn(1, in_chans_sag, 84, 160)\n",
    "            sample_input_axi = torch.randn(1, in_chans_axi, 224, 224)\n",
    "            output_sag = self.model_sag(sample_input_sag)\n",
    "            output_axi = self.model_axi(sample_input_axi)\n",
    "        \n",
    "        # Define the final fully connected layers for each task\n",
    "        self.fc_heads = nn.ModuleDict({\n",
    "            level: LevelHead(output_sag.shape[1] + output_axi.shape[1], num_classes) for level in level_names\n",
    "        })\n",
    "        \n",
    "    def forward(self, x_sag, x_axi, level):\n",
    "        x_sag = self.model_sag(x_sag)\n",
    "        x_axi = self.model_axi(x_axi)\n",
    "        x = torch.cat((x_sag, x_axi), dim=1)\n",
    "        x = self.fc_heads[level[0]](x) # the input level is a array associated with batch size\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f28b535",
   "metadata": {
    "papermill": {
     "duration": 0.008758,
     "end_time": "2024-10-03T05:02:28.052394",
     "exception": false,
     "start_time": "2024-10-03T05:02:28.043636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68a78143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:28.071042Z",
     "iopub.status.busy": "2024-10-03T05:02:28.070804Z",
     "iopub.status.idle": "2024-10-03T05:02:28.079773Z",
     "shell.execute_reply": "2024-10-03T05:02:28.079105Z"
    },
    "papermill": {
     "duration": 0.020623,
     "end_time": "2024-10-03T05:02:28.081803",
     "exception": false,
     "start_time": "2024-10-03T05:02:28.061180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CKPT_PATHS = glob.glob('/kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-*.pt')\n",
    "CKPT_PATHS = sorted(CKPT_PATHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6a14c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:28.100643Z",
     "iopub.status.busy": "2024-10-03T05:02:28.100405Z",
     "iopub.status.idle": "2024-10-03T05:02:38.323342Z",
     "shell.execute_reply": "2024-10-03T05:02:38.322387Z"
    },
    "papermill": {
     "duration": 10.234513,
     "end_time": "2024-10-03T05:02:38.325359",
     "exception": false,
     "start_time": "2024-10-03T05:02:28.090846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-0.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-1.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-2.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-3.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-4.pt...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(models)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure device is set correctly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = []\n",
    "for i, cp in enumerate(CKPT_PATHS):\n",
    "    print(f'loading {cp}...')\n",
    "    model = RSNA24Model_Hybrid(model_name_sag, model_name_axi,\n",
    "                               in_chans_sag, in_chans_axi, \n",
    "                               num_classes=N_CLASSES, level_names=level_mapping.keys())\n",
    "    model.load_state_dict(torch.load(cp, map_location=device))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "'''print(models)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb226d8",
   "metadata": {
    "papermill": {
     "duration": 0.009161,
     "end_time": "2024-10-03T05:02:38.344182",
     "exception": false,
     "start_time": "2024-10-03T05:02:38.335021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d4ad8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:38.364400Z",
     "iopub.status.busy": "2024-10-03T05:02:38.364083Z",
     "iopub.status.idle": "2024-10-03T05:02:39.975322Z",
     "shell.execute_reply": "2024-10-03T05:02:39.974327Z"
    },
    "papermill": {
     "duration": 1.624463,
     "end_time": "2024-10-03T05:02:39.978039",
     "exception": false,
     "start_time": "2024-10-03T05:02:38.353576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "y_preds = []\n",
    "row_names = []\n",
    "\n",
    "seq_cond = [1, 3, 2, 4, 0]\n",
    "with tqdm(test_dl, leave=True) as pbar:\n",
    "    with torch.no_grad():\n",
    "        for idx, (st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels) in enumerate(pbar):\n",
    "            pred_per_study = np.zeros((25, 3))\n",
    "            index = 0  # Initialize the index counter\n",
    "            for npy_sagT1, npy_sagT2, npy_AxiT2, level in zip(npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels):        \n",
    "                pred_per_study_level = np.zeros((5, 3))  \n",
    "                npy_sagT1 = npy_sagT1.to(device)\n",
    "                npy_sagT2 = npy_sagT2.to(device)\n",
    "                npy_AxiT2 = npy_AxiT2.to(device)\n",
    "                with torch.cuda.amp.autocast(): \n",
    "                    for m in models:    \n",
    "                        y = m(torch.cat((npy_sagT1, npy_sagT2), axis=1), npy_AxiT2, level)[0]\n",
    "                        for col in range(N_LABELS):\n",
    "                            pred = y[col*3:col*3+3]\n",
    "                            y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "                            pred_per_study_level[col] += y_pred / len(models)\n",
    "                    # pred_per_study_level (5, 3)\n",
    "                for i in range(5):\n",
    "                    pred_per_study[index + i*5, :] = pred_per_study_level[seq_cond[i], :]\n",
    "                index += 1  # Increment the index for the next iteration\n",
    "\n",
    "            # Add row names following the new sequence\n",
    "            for cond_idx in seq_cond:\n",
    "                cond = CONDITIONS[cond_idx]\n",
    "                for i in range(5):\n",
    "                    row_name = f\"{str(st_id.item())}_{cond}_{level_mapping[''.join(levels[i])]}\"\n",
    "                    row_names.append(row_name)\n",
    "            \n",
    "            y_preds.append(pred_per_study)\n",
    "        \n",
    "y_preds = np.concatenate(y_preds, axis=0)\n",
    "                    \n",
    "print(len(row_names))\n",
    "print(len(y_preds))\n",
    "\n",
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25eeb5f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:39.999100Z",
     "iopub.status.busy": "2024-10-03T05:02:39.998781Z",
     "iopub.status.idle": "2024-10-03T05:02:40.007621Z",
     "shell.execute_reply": "2024-10-03T05:02:40.006583Z"
    },
    "papermill": {
     "duration": 0.021661,
     "end_time": "2024-10-03T05:02:40.009638",
     "exception": false,
     "start_time": "2024-10-03T05:02:39.987977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=25, step=1)\n"
     ]
    }
   ],
   "source": [
    "sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')\n",
    "LABELS = list(sample_sub.columns[1:])\n",
    "# print(sample_sub.head(30))\n",
    "print(sample_sub.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a80cde",
   "metadata": {
    "papermill": {
     "duration": 0.009576,
     "end_time": "2024-10-03T05:02:40.029326",
     "exception": false,
     "start_time": "2024-10-03T05:02:40.019750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27564624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:40.050000Z",
     "iopub.status.busy": "2024-10-03T05:02:40.049750Z",
     "iopub.status.idle": "2024-10-03T05:02:40.053649Z",
     "shell.execute_reply": "2024-10-03T05:02:40.052842Z"
    },
    "papermill": {
     "duration": 0.016391,
     "end_time": "2024-10-03T05:02:40.055434",
     "exception": false,
     "start_time": "2024-10-03T05:02:40.039043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Check if \"row_id\" columns are the same\n",
    "# row_id_same = sub['row_id'].equals(sample_sub['row_id'])\n",
    "# print(\"Row_id columns are the same:\", row_id_same)\n",
    "\n",
    "# # If not the same, print the unequal rows\n",
    "# if not row_id_same:\n",
    "#     unequal_rows = sub[sub['row_id'] != sample_sub['row_id']]\n",
    "#     print(\"Rows with unequal 'row_id':\")\n",
    "#     print(unequal_rows)\n",
    "\n",
    "# # Check if columns are the same\n",
    "# columns_are_same = sub.columns.equals(sample_sub.columns)\n",
    "# print(\"Columns are the same:\", columns_are_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ae109f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:40.075952Z",
     "iopub.status.busy": "2024-10-03T05:02:40.075660Z",
     "iopub.status.idle": "2024-10-03T05:02:40.085816Z",
     "shell.execute_reply": "2024-10-03T05:02:40.084962Z"
    },
    "papermill": {
     "duration": 0.022939,
     "end_time": "2024-10-03T05:02:40.088052",
     "exception": false,
     "start_time": "2024-10-03T05:02:40.065113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=25, step=1)\n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['row_id'] = row_names\n",
    "sub[LABELS] = y_preds\n",
    "print(sub.index)\n",
    "# print(sub.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6263a821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T05:02:40.109109Z",
     "iopub.status.busy": "2024-10-03T05:02:40.108870Z",
     "iopub.status.idle": "2024-10-03T05:02:40.116898Z",
     "shell.execute_reply": "2024-10-03T05:02:40.116060Z"
    },
    "papermill": {
     "duration": 0.020773,
     "end_time": "2024-10-03T05:02:40.118790",
     "exception": false,
     "start_time": "2024-10-03T05:02:40.098017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pd.read_csv('submission.csv').head()\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub.to_csv('submission.csv', index=False)\n",
    "'''pd.read_csv('submission.csv').head()'''\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "datasetId": 5471909,
     "sourceId": 9529005,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 198313435,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199001269,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199192833,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.847753,
   "end_time": "2024-10-03T05:02:41.449654",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-03T05:01:58.601901",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
