{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a67654",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.008625,
     "end_time": "2024-10-02T12:39:37.401278",
     "exception": false,
     "start_time": "2024-10-02T12:39:37.392653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adopted from https://www.kaggle.com/code/yxyyxy/rsna2024-training-baseline-2nd-stage/edit\n",
    "\n",
    "# RSNA2024 LSDC Submission Baseline\n",
    "\n",
    "This notebook will Let the model infer and make a submission.\n",
    "\n",
    "### My other Notebooks\n",
    "- [RSNA2024 LSDC Making Dataset](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-making-dataset) \n",
    "- [RSNA2024 LSDC Training Baseline](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-training-baseline) \n",
    "- [RSNA2024 LSDC Submission Baseline](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline) <- you're reading now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aab0d9",
   "metadata": {
    "papermill": {
     "duration": 0.007757,
     "end_time": "2024-10-02T12:39:37.417091",
     "exception": false,
     "start_time": "2024-10-02T12:39:37.409334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f8a5dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:39:37.433960Z",
     "iopub.status.busy": "2024-10-02T12:39:37.433197Z",
     "iopub.status.idle": "2024-10-02T12:39:37.444698Z",
     "shell.execute_reply": "2024-10-02T12:39:37.443776Z"
    },
    "papermill": {
     "duration": 0.022125,
     "end_time": "2024-10-02T12:39:37.446565",
     "exception": false,
     "start_time": "2024-10-02T12:39:37.424440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "if DEBUG == True:\n",
    "    rd = '/kaggle/input/rsna-lsdc-2024-submission-debug-dataset/debug'\n",
    "else:\n",
    "    rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "    \n",
    "# Define the directory path\n",
    "DATA_fromStage1 = '/kaggle/working'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3784c46b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:39:37.462405Z",
     "iopub.status.busy": "2024-10-02T12:39:37.462140Z",
     "iopub.status.idle": "2024-10-02T12:39:58.727435Z",
     "shell.execute_reply": "2024-10-02T12:39:58.726285Z"
    },
    "papermill": {
     "duration": 21.275727,
     "end_time": "2024-10-02T12:39:58.729750",
     "exception": false,
     "start_time": "2024-10-02T12:39:37.454023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using path: /kaggle/input/2d-segmentation-of-sagittal-lumbar-spine-mri/simple_unet.pth\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\r\n",
      "  warnings.warn(msg)\r\n",
      "Using path: /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\r\n",
      "Using base path: /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images\r\n",
      "Processing studies: 100%|█████████████████████████| 1/1 [00:08<00:00,  8.21s/it]\r\n",
      "Pipeline completed successfully!\r\n",
      "Processing studies: 100%|█████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\r\n",
      "Axial dataset generation completed successfully!\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/input/script-deepspine-custom-dataset/main.py \\\n",
    "\"{rd}/test_series_descriptions.csv\" \\\n",
    "\"{rd}/sample_submission.csv\" \\\n",
    "\"{rd}/test_images\" \\\n",
    "'/kaggle/input/2d-segmentation-of-sagittal-lumbar-spine-mri/simple_unet.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd773f65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:39:58.747684Z",
     "iopub.status.busy": "2024-10-02T12:39:58.747101Z",
     "iopub.status.idle": "2024-10-02T12:40:03.757241Z",
     "shell.execute_reply": "2024-10-02T12:40:03.756298Z"
    },
    "papermill": {
     "duration": 5.021464,
     "end_time": "2024-10-02T12:40:03.759524",
     "exception": false,
     "start_time": "2024-10-02T12:39:58.738060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import timm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd9ec0",
   "metadata": {
    "papermill": {
     "duration": 0.00778,
     "end_time": "2024-10-02T12:40:03.775590",
     "exception": false,
     "start_time": "2024-10-02T12:40:03.767810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cb773e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:03.793252Z",
     "iopub.status.busy": "2024-10-02T12:40:03.792374Z",
     "iopub.status.idle": "2024-10-02T12:40:03.862382Z",
     "shell.execute_reply": "2024-10-02T12:40:03.861623Z"
    },
    "papermill": {
     "duration": 0.080888,
     "end_time": "2024-10-02T12:40:03.864351",
     "exception": false,
     "start_time": "2024-10-02T12:40:03.783463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "N_WORKERS = os.cpu_count()\n",
    "USE_AMP = True\n",
    "SEED = 1\n",
    "\n",
    "IMG_SIZE = [224, 224]\n",
    "N_LABELS = 5\n",
    "N_CLASSES = 3 * N_LABELS\n",
    "\n",
    "model_name_sag = 'efficientnet_b0'\n",
    "model_name_axi = 'resnet34'\n",
    "# resnet34\n",
    "in_chans_sag = 30\n",
    "in_chans_axi = 4\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef51e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:03.882989Z",
     "iopub.status.busy": "2024-10-02T12:40:03.882389Z",
     "iopub.status.idle": "2024-10-02T12:40:03.889183Z",
     "shell.execute_reply": "2024-10-02T12:40:03.888380Z"
    },
    "papermill": {
     "duration": 0.017552,
     "end_time": "2024-10-02T12:40:03.891174",
     "exception": false,
     "start_time": "2024-10-02T12:40:03.873622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44a5ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:03.908187Z",
     "iopub.status.busy": "2024-10-02T12:40:03.907939Z",
     "iopub.status.idle": "2024-10-02T12:40:03.912680Z",
     "shell.execute_reply": "2024-10-02T12:40:03.911894Z"
    },
    "papermill": {
     "duration": 0.015652,
     "end_time": "2024-10-02T12:40:03.914843",
     "exception": false,
     "start_time": "2024-10-02T12:40:03.899191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "\n",
    "# Define the mapping for each level\n",
    "level_mapping = {\n",
    "    'L1/L2': 'l1_l2',\n",
    "    'L2/L3': 'l2_l3',\n",
    "    'L3/L4': 'l3_l4',\n",
    "    'L4/L5': 'l4_l5',\n",
    "    'L5/S1': 'l5_s1'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b0ff56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:03.932117Z",
     "iopub.status.busy": "2024-10-02T12:40:03.931812Z",
     "iopub.status.idle": "2024-10-02T12:40:03.936266Z",
     "shell.execute_reply": "2024-10-02T12:40:03.935589Z"
    },
    "papermill": {
     "duration": 0.015376,
     "end_time": "2024-10-02T12:40:03.938093",
     "exception": false,
     "start_time": "2024-10-02T12:40:03.922717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e443ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:03.954879Z",
     "iopub.status.busy": "2024-10-02T12:40:03.954627Z",
     "iopub.status.idle": "2024-10-02T12:40:03.972994Z",
     "shell.execute_reply": "2024-10-02T12:40:03.972143Z"
    },
    "papermill": {
     "duration": 0.028772,
     "end_time": "2024-10-02T12:40:03.974780",
     "exception": false,
     "start_time": "2024-10-02T12:40:03.946008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L4/L5</th>\n",
       "      <th>L3/L4</th>\n",
       "      <th>L2/L3</th>\n",
       "      <th>L1/L2</th>\n",
       "      <th>L5/S1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>st_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44036939</th>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L4_L5.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L3_L4.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L2_L3.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L1_L2.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L5_S1.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  L4/L5  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L4_L5.npy   \n",
       "\n",
       "                                                  L3/L4  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L3_L4.npy   \n",
       "\n",
       "                                                  L2/L3  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L2_L3.npy   \n",
       "\n",
       "                                                  L1/L2  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L1_L2.npy   \n",
       "\n",
       "                                                  L5/S1  \n",
       "st_id                                                    \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L5_S1.npy  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to CSV file\n",
    "csv_file_path = DATA_fromStage1 + '/sagittalT2/dataset_metadata.csv'\n",
    "# Read the CSV file\n",
    "dataset_metadata = pd.read_csv(csv_file_path)\n",
    "dataset_metadata.rename(columns={'Unnamed: 0': 'st_id'}, inplace=True)\n",
    "dataset_metadata.set_index('st_id', inplace=True)\n",
    "\n",
    "\n",
    "# # Print the number of columns and rows in the DataFrame\n",
    "# num_rows = dataset_metadata.shape[0]\n",
    "# print(f\"columns: {dataset_metadata.columns}\")\n",
    "# print(f\"Number of rows: {num_rows}\")\n",
    "\n",
    "# # print(dataset_metadata.head())\n",
    "# # Stack the 2nd to 6th columns into a single column\n",
    "# stacked_df = dataset_metadata.stack(dropna=False).reset_index(level=1)\n",
    "# stacked_df.columns = ['Level', 'fn']\n",
    "'''# stacked_df = stacked_df.reset_index(drop=True)\n",
    "print(stacked_df)\n",
    "\n",
    "print(\"----------- test index 0 -------------\")\n",
    "st_id = stacked_df.index[0]\n",
    "row_idx = stacked_df.iloc[0]\n",
    "print(st_id)\n",
    "print(row_idx['Level'])\n",
    "print(row_idx['fn'])\n",
    "print(\"----------- test index 1 -------------\")\n",
    "st_id = stacked_df.index[1]\n",
    "row_idx = stacked_df.iloc[1]\n",
    "print(st_id)\n",
    "print(row_idx['Level'])\n",
    "print(row_idx['fn'])'''\n",
    "\n",
    "dataset_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b0dac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:03.992546Z",
     "iopub.status.busy": "2024-10-02T12:40:03.992310Z",
     "iopub.status.idle": "2024-10-02T12:40:03.999026Z",
     "shell.execute_reply": "2024-10-02T12:40:03.998267Z"
    },
    "papermill": {
     "duration": 0.017752,
     "end_time": "2024-10-02T12:40:04.000909",
     "exception": false,
     "start_time": "2024-10-02T12:40:03.983157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# one npy file example\\nprint(\"--------------------- SagittalT2 samples -----------\")\\nexample_npy_fn = dataset_metadata[\\'L4/L5\\'][0]\\nexample_npy_fn = example_npy_fn.split(\\'/\\')\\n# Load the .npy file\\nexample_npy = np.load(os.path.join(DATA_fromStage1, *(example_npy_fn[-3:])))\\n# Print the structure of the data\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\n# Show the 15 slices one by one\\nfor i in range(15):\\n    plt.imshow(example_npy[i], cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n\\nprint(\"--------------------- SagittalT1 samples -----------\")\\nexample_npy = np.load(os.path.join(DATA_fromStage1, \\'sagittalT1\\', *(example_npy_fn[-2:])))\\n# Print the structure of the data\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\n# Show the 15 slices one by one\\nfor i in range(15):\\n    plt.imshow(example_npy[i], cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n\\nprint(\"--------------------- AxialT2 samples ----------\")\\n# Load the .npy file\\nexample_npy = np.load(os.path.join(DATA_fromStage1, \\'axialT2\\', *(example_npy_fn[-2:])))\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\nfor i in range(6):\\n    img = example_npy[i]\\n    plt.imshow(img, cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# one npy file example\n",
    "print(\"--------------------- SagittalT2 samples -----------\")\n",
    "example_npy_fn = dataset_metadata['L4/L5'][0]\n",
    "example_npy_fn = example_npy_fn.split('/')\n",
    "# Load the .npy file\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, *(example_npy_fn[-3:])))\n",
    "# Print the structure of the data\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "# Show the 15 slices one by one\n",
    "for i in range(15):\n",
    "    plt.imshow(example_npy[i], cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"--------------------- SagittalT1 samples -----------\")\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, 'sagittalT1', *(example_npy_fn[-2:])))\n",
    "# Print the structure of the data\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "# Show the 15 slices one by one\n",
    "for i in range(15):\n",
    "    plt.imshow(example_npy[i], cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"--------------------- AxialT2 samples ----------\")\n",
    "# Load the .npy file\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, 'axialT2', *(example_npy_fn[-2:])))\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "for i in range(6):\n",
    "    img = example_npy[i]\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076ec2d",
   "metadata": {
    "papermill": {
     "duration": 0.008099,
     "end_time": "2024-10-02T12:40:04.017309",
     "exception": false,
     "start_time": "2024-10-02T12:40:04.009210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baadb92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:04.035295Z",
     "iopub.status.busy": "2024-10-02T12:40:04.034988Z",
     "iopub.status.idle": "2024-10-02T12:40:04.054198Z",
     "shell.execute_reply": "2024-10-02T12:40:04.053433Z"
    },
    "papermill": {
     "duration": 0.030504,
     "end_time": "2024-10-02T12:40:04.056020",
     "exception": false,
     "start_time": "2024-10-02T12:40:04.025516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RSNA24TestDataset(Dataset):\n",
    "    def __init__(self, df_fn, Slice_len_Sag=15, Slice_len_Axi=4, transform=None, trainsform_axis=None):\n",
    "        self.df_fn = df_fn\n",
    "        self.transform = transform\n",
    "        self.trainsform_axis = trainsform_axis\n",
    "        self.Slice_len_Sag = Slice_len_Sag\n",
    "        self.Slice_len_Axi = Slice_len_Axi\n",
    "        # Select all rows where the 'Name' column has the value 'Alice'\n",
    "    def __len__(self):\n",
    "        return len(self.df_fn)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        st_id = self.df_fn.index[idx]\n",
    "        row_idx = self.df_fn.iloc[idx]\n",
    "        levels = ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']\n",
    "        filenames = [row_idx[level] for level in levels]\n",
    "        \n",
    "        npy_sagT2_list = []\n",
    "        npy_sagT1_list = []\n",
    "        npy_AxiT2_list = []\n",
    "    \n",
    "        for filename in filenames:\n",
    "            path_split = filename.split('/')\n",
    "            \n",
    "            # Saggital T2 ------------  Load the .npy file\n",
    "            npy_sagT2_path = os.path.join(DATA_fromStage1, path_split[3], path_split[4], path_split[5])\n",
    "            npy_sagT2 = np.load(npy_sagT2_path).astype(np.float32)\n",
    "            current_length = npy_sagT2.shape[0]\n",
    "            if current_length > self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT2 = npy_sagT2[indices, :, :]\n",
    "            elif current_length < self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT2 = npy_sagT2[indices, :, :]\n",
    "            npy_sagT2_list.append(npy_sagT2)\n",
    "            # Saggital T1 ------------  Load the .npy file\n",
    "            npy_sagT1_path = os.path.join(DATA_fromStage1, \"sagittalT1\", path_split[4], path_split[5])\n",
    "            npy_sagT1 = np.load(npy_sagT1_path).astype(np.float32)\n",
    "            current_length = npy_sagT1.shape[0]\n",
    "            if current_length > self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT1 = npy_sagT1[indices, :, :]\n",
    "            elif current_length < self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT1 = npy_sagT1[indices, :, :]\n",
    "            npy_sagT1_list.append(npy_sagT1)\n",
    "            # Axial T2 ------------ Load the .npy file\n",
    "            npy_AxiT2_path = os.path.join(DATA_fromStage1 , \"axialT2\", path_split[4], path_split[5])\n",
    "            npy_AxiT2 = np.load(npy_AxiT2_path).astype(np.float32)\n",
    "            current_length = npy_AxiT2.shape[0]\n",
    "            if current_length > self.Slice_len_Axi:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Axi, dtype=int)\n",
    "                npy_AxiT2 = npy_AxiT2[indices, :, :]\n",
    "            elif current_length < self.Slice_len_Axi:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Axi, dtype=int)\n",
    "                npy_AxiT2 = npy_AxiT2[indices, :, :]\n",
    "            npy_AxiT2_list.append(npy_AxiT2)\n",
    "            \n",
    "        # Transpose and transform the data\n",
    "        npy_sagT1_list = [np.transpose(npy, (1, 2, 0)) for npy in npy_sagT1_list]\n",
    "        npy_sagT2_list = [np.transpose(npy, (1, 2, 0)) for npy in npy_sagT2_list]\n",
    "        npy_AxiT2_list = [np.transpose(npy, (1, 2, 0)) for npy in npy_AxiT2_list]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            npy_sagT1_list = [self.transform(image=npy)['image'] for npy in npy_sagT1_list]\n",
    "            npy_sagT2_list = [self.transform(image=npy)['image'] for npy in npy_sagT2_list]\n",
    "            npy_AxiT2_list = [self.trainsform_axis(image=npy)['image'] for npy in npy_AxiT2_list]\n",
    "\n",
    "        # Transpose back to the original format\n",
    "        npy_sagT1_list = [np.transpose(npy, (2, 0, 1)) for npy in npy_sagT1_list]\n",
    "        npy_sagT2_list = [np.transpose(npy, (2, 0, 1)) for npy in npy_sagT2_list]\n",
    "        npy_AxiT2_list = [np.transpose(npy, (2, 0, 1)) for npy in npy_AxiT2_list]\n",
    "\n",
    "        return st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e61322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:04.073560Z",
     "iopub.status.busy": "2024-10-02T12:40:04.073297Z",
     "iopub.status.idle": "2024-10-02T12:40:04.078320Z",
     "shell.execute_reply": "2024-10-02T12:40:04.077437Z"
    },
    "papermill": {
     "duration": 0.015928,
     "end_time": "2024-10-02T12:40:04.080161",
     "exception": false,
     "start_time": "2024-10-02T12:40:04.064233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms_test_Sag = A.Compose([\n",
    "    A.Resize(84, 160),\n",
    "    A.Normalize(mean=0.5, std=0.5)\n",
    "])\n",
    "\n",
    "transforms_test = A.Compose([\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "    A.Normalize(mean=0.5, std=0.5)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e21438db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:04.098488Z",
     "iopub.status.busy": "2024-10-02T12:40:04.097605Z",
     "iopub.status.idle": "2024-10-02T12:40:04.103082Z",
     "shell.execute_reply": "2024-10-02T12:40:04.102311Z"
    },
    "papermill": {
     "duration": 0.0166,
     "end_time": "2024-10-02T12:40:04.105018",
     "exception": false,
     "start_time": "2024-10-02T12:40:04.088418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = RSNA24TestDataset(dataset_metadata, transform=transforms_test_Sag, trainsform_axis=transforms_test)\n",
    "test_dl = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=1, \n",
    "    shuffle=False,\n",
    "    num_workers=N_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93136111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:04.122633Z",
     "iopub.status.busy": "2024-10-02T12:40:04.122338Z",
     "iopub.status.idle": "2024-10-02T12:40:04.128751Z",
     "shell.execute_reply": "2024-10-02T12:40:04.127918Z"
    },
    "papermill": {
     "duration": 0.017405,
     "end_time": "2024-10-02T12:40:04.130706",
     "exception": false,
     "start_time": "2024-10-02T12:40:04.113301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from collections import Counter\\n\\nsagT2_slicenum = []\\nAxiT2_slicenum = []\\n\\nprint(test_dl.__len__())\\n\\n# Iterate through the data loader and append slice numbers\\nfor idx, (st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels) in enumerate(test_dl):\\n    for npy_sagT2 in npy_sagT2_list:\\n        sagT2_slicenum.append(npy_sagT2.shape)\\n        assert not torch.isnan(npy_sagT2).any(), \"NaN values found in npy_sagT2\"\\n    \\n    for npy_AxiT2 in npy_AxiT2_list:\\n        AxiT2_slicenum.append(npy_AxiT2.shape)\\n        assert not torch.isnan(npy_AxiT2).any(), \"NaN values found in npy_AxiT2\"\\n    \\n    print(f\"Batch {idx + 1}: Levels - {levels}\")\\n\\n# Count the occurrences of each unique value in the lists\\nsagT2_counts = Counter(sagT2_slicenum)\\nAxiT2_counts = Counter(AxiT2_slicenum)\\n\\nprint(\"Occurrences of each unique value in sagT2_slicenum:\")\\nfor value, count in sagT2_counts.items():\\n    print(f\"Value: {value}, Count: {count}\")\\n\\nprint(\"Occurrences of each unique value in AxiT2_slicenum:\")\\nfor value, count in AxiT2_counts.items():\\n    print(f\"Value: {value}, Count: {count}\")'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from collections import Counter\n",
    "\n",
    "sagT2_slicenum = []\n",
    "AxiT2_slicenum = []\n",
    "\n",
    "print(test_dl.__len__())\n",
    "\n",
    "# Iterate through the data loader and append slice numbers\n",
    "for idx, (st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels) in enumerate(test_dl):\n",
    "    for npy_sagT2 in npy_sagT2_list:\n",
    "        sagT2_slicenum.append(npy_sagT2.shape)\n",
    "        assert not torch.isnan(npy_sagT2).any(), \"NaN values found in npy_sagT2\"\n",
    "    \n",
    "    for npy_AxiT2 in npy_AxiT2_list:\n",
    "        AxiT2_slicenum.append(npy_AxiT2.shape)\n",
    "        assert not torch.isnan(npy_AxiT2).any(), \"NaN values found in npy_AxiT2\"\n",
    "    \n",
    "    print(f\"Batch {idx + 1}: Levels - {levels}\")\n",
    "\n",
    "# Count the occurrences of each unique value in the lists\n",
    "sagT2_counts = Counter(sagT2_slicenum)\n",
    "AxiT2_counts = Counter(AxiT2_slicenum)\n",
    "\n",
    "print(\"Occurrences of each unique value in sagT2_slicenum:\")\n",
    "for value, count in sagT2_counts.items():\n",
    "    print(f\"Value: {value}, Count: {count}\")\n",
    "\n",
    "print(\"Occurrences of each unique value in AxiT2_slicenum:\")\n",
    "for value, count in AxiT2_counts.items():\n",
    "    print(f\"Value: {value}, Count: {count}\")'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f628b3",
   "metadata": {
    "papermill": {
     "duration": 0.008397,
     "end_time": "2024-10-02T12:40:04.147602",
     "exception": false,
     "start_time": "2024-10-02T12:40:04.139205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2858b75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:04.165705Z",
     "iopub.status.busy": "2024-10-02T12:40:04.165464Z",
     "iopub.status.idle": "2024-10-02T12:40:04.179489Z",
     "shell.execute_reply": "2024-10-02T12:40:04.178715Z"
    },
    "papermill": {
     "duration": 0.02516,
     "end_time": "2024-10-02T12:40:04.181257",
     "exception": false,
     "start_time": "2024-10-02T12:40:04.156097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ComplexHead(nn.Module):\n",
    "    def __init__(self, input_dim1, input_dim2, num_classes):\n",
    "        super(ComplexHead, self).__init__()\n",
    "        self.fc1_sag = nn.Linear(input_dim1, 256)\n",
    "        self.fc1_axi = nn.Linear(input_dim2, 1024)\n",
    "        self.fc2_axi = nn.Linear(1024, 256)\n",
    "        self.fc2 = nn.Linear(512, 128)  # Combined input size\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.batchnorm1_sag = nn.BatchNorm1d(256)\n",
    "        self.batchnorm1_axi = nn.BatchNorm1d(1024)\n",
    "        self.batchnorm2_axi = nn.BatchNorm1d(256)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x_sag, x_axi):\n",
    "        x_sag = torch.relu(self.batchnorm1_sag(self.fc1_sag(x_sag)))\n",
    "        x_axi = torch.relu(self.batchnorm1_axi(self.fc1_axi(x_axi)))\n",
    "        x_axi = torch.relu(self.batchnorm2_axi(self.fc2_axi(x_axi)))\n",
    "        \n",
    "        # Concatenate the outputs from both inputs\n",
    "        x = torch.cat((x_sag, x_axi), dim=1)\n",
    "        \n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.batchnorm2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class RSNA24Model_Hybrid(nn.Module):\n",
    "    def __init__(self, model_name_sag, model_name_axi, in_chans_sag, in_chans_axi, num_classes, level_names):\n",
    "        super(RSNA24Model_Hybrid, self).__init__()\n",
    "        self.model_sag = timm.create_model(model_name_sag, in_chans=in_chans_sag, global_pool='avg', pretrained=False, features_only=True)\n",
    "        self.model_axi = timm.create_model(model_name_axi, in_chans=in_chans_axi, global_pool='avg', pretrained=False, features_only=True)\n",
    "        \n",
    "        # Define the final fully connected layers for each task\n",
    "        self.fc_heads = nn.ModuleDict({\n",
    "            level: ComplexHead(input_dim1=320*3*5, input_dim2=512*7*7, num_classes=num_classes) for level in level_names\n",
    "        })\n",
    "    \n",
    "    def forward(self, x_sag, x_axi, level):\n",
    "        x_sag = self.model_sag(x_sag)[-1]\n",
    "        x_axi = self.model_axi(x_axi)[-1]\n",
    "        x_sag = x_sag.reshape(x_sag.size(0), -1)\n",
    "        x_axi = x_axi.reshape(x_axi.size(0), -1)\n",
    "        x = self.fc_heads[level[0]](x_sag, x_axi) # the input level is a array associated with batch size\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c4c3a",
   "metadata": {
    "papermill": {
     "duration": 0.008191,
     "end_time": "2024-10-02T12:40:04.197949",
     "exception": false,
     "start_time": "2024-10-02T12:40:04.189758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40fe7672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:04.215691Z",
     "iopub.status.busy": "2024-10-02T12:40:04.215435Z",
     "iopub.status.idle": "2024-10-02T12:40:04.227512Z",
     "shell.execute_reply": "2024-10-02T12:40:04.226887Z"
    },
    "papermill": {
     "duration": 0.023007,
     "end_time": "2024-10-02T12:40:04.229316",
     "exception": false,
     "start_time": "2024-10-02T12:40:04.206309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "CKPT_PATHS = glob.glob('/kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-*.pt')\n",
    "CKPT_PATHS = sorted(CKPT_PATHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5c81f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:04.246981Z",
     "iopub.status.busy": "2024-10-02T12:40:04.246699Z",
     "iopub.status.idle": "2024-10-02T12:40:39.712328Z",
     "shell.execute_reply": "2024-10-02T12:40:39.711357Z"
    },
    "papermill": {
     "duration": 35.484881,
     "end_time": "2024-10-02T12:40:39.722520",
     "exception": false,
     "start_time": "2024-10-02T12:40:04.237639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-0.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-1.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-2.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-3.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-4.pt...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(models)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure device is set correctly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = []\n",
    "for i, cp in enumerate(CKPT_PATHS):\n",
    "    print(f'loading {cp}...')\n",
    "    model = RSNA24Model_Hybrid(model_name_sag, model_name_axi,\n",
    "                               in_chans_sag, in_chans_axi, \n",
    "                               num_classes=N_CLASSES, level_names=level_mapping.keys())\n",
    "    model.load_state_dict(torch.load(cp, map_location=device))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "'''print(models)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa4553",
   "metadata": {
    "papermill": {
     "duration": 0.008674,
     "end_time": "2024-10-02T12:40:39.740168",
     "exception": false,
     "start_time": "2024-10-02T12:40:39.731494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e885ce9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:39.759452Z",
     "iopub.status.busy": "2024-10-02T12:40:39.759120Z",
     "iopub.status.idle": "2024-10-02T12:40:41.453753Z",
     "shell.execute_reply": "2024-10-02T12:40:41.452745Z"
    },
    "papermill": {
     "duration": 1.707849,
     "end_time": "2024-10-02T12:40:41.456935",
     "exception": false,
     "start_time": "2024-10-02T12:40:39.749086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "y_preds = []\n",
    "row_names = []\n",
    "\n",
    "seq_cond = [1, 3, 2, 4, 0]\n",
    "with tqdm(test_dl, leave=True) as pbar:\n",
    "    with torch.no_grad():\n",
    "        for idx, (st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels) in enumerate(pbar):\n",
    "            pred_per_study = np.zeros((25, 3))\n",
    "            index = 0  # Initialize the index counter\n",
    "            for npy_sagT1, npy_sagT2, npy_AxiT2, level in zip(npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels):        \n",
    "                pred_per_study_level = np.zeros((5, 3))  \n",
    "                npy_sagT1 = npy_sagT1.to(device)\n",
    "                npy_sagT2 = npy_sagT2.to(device)\n",
    "                npy_AxiT2 = npy_AxiT2.to(device)\n",
    "                with torch.cuda.amp.autocast(): \n",
    "                    for m in models:    \n",
    "                        y = m(torch.cat((npy_sagT1, npy_sagT2), axis=1), npy_AxiT2, level)[0]\n",
    "                        for col in range(N_LABELS):\n",
    "                            pred = y[col*3:col*3+3]\n",
    "                            y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "                            pred_per_study_level[col] += y_pred / len(models)\n",
    "                    # pred_per_study_level (5, 3)\n",
    "                for i in range(5):\n",
    "                    pred_per_study[index + i*5, :] = pred_per_study_level[seq_cond[i], :]\n",
    "                index += 1  # Increment the index for the next iteration\n",
    "\n",
    "            # Add row names following the new sequence\n",
    "            for cond_idx in seq_cond:\n",
    "                cond = CONDITIONS[cond_idx]\n",
    "                for i in range(5):\n",
    "                    row_name = f\"{str(st_id.item())}_{cond}_{level_mapping[''.join(levels[i])]}\"\n",
    "                    row_names.append(row_name)\n",
    "            \n",
    "            y_preds.append(pred_per_study)\n",
    "        \n",
    "y_preds = np.concatenate(y_preds, axis=0)\n",
    "                    \n",
    "print(len(row_names))\n",
    "print(len(y_preds))\n",
    "\n",
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99b2e775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:41.477277Z",
     "iopub.status.busy": "2024-10-02T12:40:41.476959Z",
     "iopub.status.idle": "2024-10-02T12:40:41.491054Z",
     "shell.execute_reply": "2024-10-02T12:40:41.489898Z"
    },
    "papermill": {
     "duration": 0.026391,
     "end_time": "2024-10-02T12:40:41.492879",
     "exception": false,
     "start_time": "2024-10-02T12:40:41.466488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             row_id  normal_mild  moderate  \\\n",
      "0    44036939_left_neural_foraminal_narrowing_l1_l2     0.333333  0.333333   \n",
      "1    44036939_left_neural_foraminal_narrowing_l2_l3     0.333333  0.333333   \n",
      "2    44036939_left_neural_foraminal_narrowing_l3_l4     0.333333  0.333333   \n",
      "3    44036939_left_neural_foraminal_narrowing_l4_l5     0.333333  0.333333   \n",
      "4    44036939_left_neural_foraminal_narrowing_l5_s1     0.333333  0.333333   \n",
      "5         44036939_left_subarticular_stenosis_l1_l2     0.333333  0.333333   \n",
      "6         44036939_left_subarticular_stenosis_l2_l3     0.333333  0.333333   \n",
      "7         44036939_left_subarticular_stenosis_l3_l4     0.333333  0.333333   \n",
      "8         44036939_left_subarticular_stenosis_l4_l5     0.333333  0.333333   \n",
      "9         44036939_left_subarticular_stenosis_l5_s1     0.333333  0.333333   \n",
      "10  44036939_right_neural_foraminal_narrowing_l1_l2     0.333333  0.333333   \n",
      "11  44036939_right_neural_foraminal_narrowing_l2_l3     0.333333  0.333333   \n",
      "12  44036939_right_neural_foraminal_narrowing_l3_l4     0.333333  0.333333   \n",
      "13  44036939_right_neural_foraminal_narrowing_l4_l5     0.333333  0.333333   \n",
      "14  44036939_right_neural_foraminal_narrowing_l5_s1     0.333333  0.333333   \n",
      "15       44036939_right_subarticular_stenosis_l1_l2     0.333333  0.333333   \n",
      "16       44036939_right_subarticular_stenosis_l2_l3     0.333333  0.333333   \n",
      "17       44036939_right_subarticular_stenosis_l3_l4     0.333333  0.333333   \n",
      "18       44036939_right_subarticular_stenosis_l4_l5     0.333333  0.333333   \n",
      "19       44036939_right_subarticular_stenosis_l5_s1     0.333333  0.333333   \n",
      "20             44036939_spinal_canal_stenosis_l1_l2     0.333333  0.333333   \n",
      "21             44036939_spinal_canal_stenosis_l2_l3     0.333333  0.333333   \n",
      "22             44036939_spinal_canal_stenosis_l3_l4     0.333333  0.333333   \n",
      "23             44036939_spinal_canal_stenosis_l4_l5     0.333333  0.333333   \n",
      "24             44036939_spinal_canal_stenosis_l5_s1     0.333333  0.333333   \n",
      "\n",
      "      severe  \n",
      "0   0.333333  \n",
      "1   0.333333  \n",
      "2   0.333333  \n",
      "3   0.333333  \n",
      "4   0.333333  \n",
      "5   0.333333  \n",
      "6   0.333333  \n",
      "7   0.333333  \n",
      "8   0.333333  \n",
      "9   0.333333  \n",
      "10  0.333333  \n",
      "11  0.333333  \n",
      "12  0.333333  \n",
      "13  0.333333  \n",
      "14  0.333333  \n",
      "15  0.333333  \n",
      "16  0.333333  \n",
      "17  0.333333  \n",
      "18  0.333333  \n",
      "19  0.333333  \n",
      "20  0.333333  \n",
      "21  0.333333  \n",
      "22  0.333333  \n",
      "23  0.333333  \n",
      "24  0.333333  \n"
     ]
    }
   ],
   "source": [
    "sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')\n",
    "LABELS = list(sample_sub.columns[1:])\n",
    "print(sample_sub.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d737dd6",
   "metadata": {
    "papermill": {
     "duration": 0.009452,
     "end_time": "2024-10-02T12:40:41.511998",
     "exception": false,
     "start_time": "2024-10-02T12:40:41.502546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0033f1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:41.532135Z",
     "iopub.status.busy": "2024-10-02T12:40:41.531564Z",
     "iopub.status.idle": "2024-10-02T12:40:41.544228Z",
     "shell.execute_reply": "2024-10-02T12:40:41.543395Z"
    },
    "papermill": {
     "duration": 0.025543,
     "end_time": "2024-10-02T12:40:41.546959",
     "exception": false,
     "start_time": "2024-10-02T12:40:41.521416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             row_id  normal_mild  moderate  \\\n",
      "0    44036939_left_neural_foraminal_narrowing_l1_l2     0.725730  0.165372   \n",
      "1    44036939_left_neural_foraminal_narrowing_l2_l3     0.561739  0.281763   \n",
      "2    44036939_left_neural_foraminal_narrowing_l3_l4     0.411123  0.414207   \n",
      "3    44036939_left_neural_foraminal_narrowing_l4_l5     0.326998  0.415019   \n",
      "4    44036939_left_neural_foraminal_narrowing_l5_s1     0.332925  0.360652   \n",
      "5         44036939_left_subarticular_stenosis_l1_l2     0.628601  0.203536   \n",
      "6         44036939_left_subarticular_stenosis_l2_l3     0.472345  0.307250   \n",
      "7         44036939_left_subarticular_stenosis_l3_l4     0.304169  0.345755   \n",
      "8         44036939_left_subarticular_stenosis_l4_l5     0.183976  0.282887   \n",
      "9         44036939_left_subarticular_stenosis_l5_s1     0.355855  0.317834   \n",
      "10  44036939_right_neural_foraminal_narrowing_l1_l2     0.724763  0.160682   \n",
      "11  44036939_right_neural_foraminal_narrowing_l2_l3     0.587520  0.264481   \n",
      "12  44036939_right_neural_foraminal_narrowing_l3_l4     0.398106  0.420968   \n",
      "13  44036939_right_neural_foraminal_narrowing_l4_l5     0.253818  0.436771   \n",
      "14  44036939_right_neural_foraminal_narrowing_l5_s1     0.331043  0.350756   \n",
      "15       44036939_right_subarticular_stenosis_l1_l2     0.641509  0.221033   \n",
      "16       44036939_right_subarticular_stenosis_l2_l3     0.491660  0.268087   \n",
      "17       44036939_right_subarticular_stenosis_l3_l4     0.294616  0.362357   \n",
      "18       44036939_right_subarticular_stenosis_l4_l5     0.176165  0.290253   \n",
      "19       44036939_right_subarticular_stenosis_l5_s1     0.408126  0.290651   \n",
      "20             44036939_spinal_canal_stenosis_l1_l2     0.698228  0.162428   \n",
      "21             44036939_spinal_canal_stenosis_l2_l3     0.558398  0.231124   \n",
      "22             44036939_spinal_canal_stenosis_l3_l4     0.404841  0.285621   \n",
      "23             44036939_spinal_canal_stenosis_l4_l5     0.313992  0.205992   \n",
      "24             44036939_spinal_canal_stenosis_l5_s1     0.738406  0.136270   \n",
      "\n",
      "      severe  \n",
      "0   0.108898  \n",
      "1   0.156499  \n",
      "2   0.174670  \n",
      "3   0.257983  \n",
      "4   0.306423  \n",
      "5   0.167862  \n",
      "6   0.220405  \n",
      "7   0.350075  \n",
      "8   0.533137  \n",
      "9   0.326311  \n",
      "10  0.114555  \n",
      "11  0.147999  \n",
      "12  0.180926  \n",
      "13  0.309410  \n",
      "14  0.318201  \n",
      "15  0.137458  \n",
      "16  0.240253  \n",
      "17  0.343027  \n",
      "18  0.533582  \n",
      "19  0.301223  \n",
      "20  0.139343  \n",
      "21  0.210478  \n",
      "22  0.309538  \n",
      "23  0.480016  \n",
      "24  0.125324  \n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['row_id'] = row_names\n",
    "sub[LABELS] = y_preds\n",
    "print(sub.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e60801e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T12:40:41.567903Z",
     "iopub.status.busy": "2024-10-02T12:40:41.567613Z",
     "iopub.status.idle": "2024-10-02T12:40:41.575872Z",
     "shell.execute_reply": "2024-10-02T12:40:41.575026Z"
    },
    "papermill": {
     "duration": 0.020502,
     "end_time": "2024-10-02T12:40:41.577695",
     "exception": false,
     "start_time": "2024-10-02T12:40:41.557193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pd.read_csv('submission.csv').head()\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.to_csv('submission.csv', index=False)\n",
    "'''pd.read_csv('submission.csv').head()'''"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "datasetId": 5471909,
     "sourceId": 9529005,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 198313435,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199001269,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199132018,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 69.210373,
   "end_time": "2024-10-02T12:40:43.826199",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-02T12:39:34.615826",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
