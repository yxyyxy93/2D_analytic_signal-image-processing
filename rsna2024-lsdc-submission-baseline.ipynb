{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959bc55b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.008119,
     "end_time": "2024-10-03T02:38:24.030787",
     "exception": false,
     "start_time": "2024-10-03T02:38:24.022668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adopted from https://www.kaggle.com/code/yxyyxy/rsna2024-training-baseline-2nd-stage/edit\n",
    "\n",
    "# RSNA2024 LSDC Submission Baseline\n",
    "\n",
    "This notebook will Let the model infer and make a submission.\n",
    "\n",
    "### My other Notebooks\n",
    "- [RSNA2024 LSDC Making Dataset](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-making-dataset) \n",
    "- [RSNA2024 LSDC Training Baseline](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-training-baseline) \n",
    "- [RSNA2024 LSDC Submission Baseline](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline) <- you're reading now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d1447",
   "metadata": {
    "papermill": {
     "duration": 0.007191,
     "end_time": "2024-10-03T02:38:24.045461",
     "exception": false,
     "start_time": "2024-10-03T02:38:24.038270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af1e506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:24.061663Z",
     "iopub.status.busy": "2024-10-03T02:38:24.061252Z",
     "iopub.status.idle": "2024-10-03T02:38:24.074130Z",
     "shell.execute_reply": "2024-10-03T02:38:24.073419Z"
    },
    "papermill": {
     "duration": 0.023159,
     "end_time": "2024-10-03T02:38:24.075985",
     "exception": false,
     "start_time": "2024-10-03T02:38:24.052826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "if DEBUG == True:\n",
    "    rd = '/kaggle/input/rsna-lsdc-2024-submission-debug-dataset/debug'\n",
    "else:\n",
    "    rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "    \n",
    "# Define the directory path\n",
    "DATA_fromStage1 = '/kaggle/working'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e9d390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:24.092168Z",
     "iopub.status.busy": "2024-10-03T02:38:24.091922Z",
     "iopub.status.idle": "2024-10-03T02:38:45.100334Z",
     "shell.execute_reply": "2024-10-03T02:38:45.099424Z"
    },
    "papermill": {
     "duration": 21.019189,
     "end_time": "2024-10-03T02:38:45.102695",
     "exception": false,
     "start_time": "2024-10-03T02:38:24.083506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using path: /kaggle/input/2d-segmentation-of-sagittal-lumbar-spine-mri/simple_unet.pth\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\r\n",
      "  warnings.warn(msg)\r\n",
      "Using path: /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\r\n",
      "Using base path: /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images\r\n",
      "Processing studies: 100%|█████████████████████████| 1/1 [00:08<00:00,  8.00s/it]\r\n",
      "Pipeline completed successfully!\r\n",
      "Processing studies: 100%|█████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\r\n",
      "Axial dataset generation completed successfully!\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/input/script-deepspine-custom-dataset/main.py \\\n",
    "\"{rd}/test_series_descriptions.csv\" \\\n",
    "\"{rd}/sample_submission.csv\" \\\n",
    "\"{rd}/test_images\" \\\n",
    "'/kaggle/input/2d-segmentation-of-sagittal-lumbar-spine-mri/simple_unet.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75a2f3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:45.120570Z",
     "iopub.status.busy": "2024-10-03T02:38:45.120273Z",
     "iopub.status.idle": "2024-10-03T02:38:50.228038Z",
     "shell.execute_reply": "2024-10-03T02:38:50.227240Z"
    },
    "papermill": {
     "duration": 5.119224,
     "end_time": "2024-10-03T02:38:50.230264",
     "exception": false,
     "start_time": "2024-10-03T02:38:45.111040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import timm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4a88d5",
   "metadata": {
    "papermill": {
     "duration": 0.007755,
     "end_time": "2024-10-03T02:38:50.246660",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.238905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987a12b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.264114Z",
     "iopub.status.busy": "2024-10-03T02:38:50.263647Z",
     "iopub.status.idle": "2024-10-03T02:38:50.332028Z",
     "shell.execute_reply": "2024-10-03T02:38:50.331209Z"
    },
    "papermill": {
     "duration": 0.079468,
     "end_time": "2024-10-03T02:38:50.333951",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.254483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "N_WORKERS = os.cpu_count()\n",
    "USE_AMP = True\n",
    "SEED = 1\n",
    "\n",
    "IMG_SIZE = [224, 224]\n",
    "N_LABELS = 5\n",
    "N_CLASSES = 3 * N_LABELS\n",
    "\n",
    "model_name_sag = 'efficientnet_b0'\n",
    "model_name_axi = 'resnet34'\n",
    "# resnet34\n",
    "in_chans_sag = 30\n",
    "in_chans_axi = 4\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50968d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.352386Z",
     "iopub.status.busy": "2024-10-03T02:38:50.352068Z",
     "iopub.status.idle": "2024-10-03T02:38:50.358840Z",
     "shell.execute_reply": "2024-10-03T02:38:50.357972Z"
    },
    "papermill": {
     "duration": 0.017657,
     "end_time": "2024-10-03T02:38:50.360701",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.343044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "814cca24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.377955Z",
     "iopub.status.busy": "2024-10-03T02:38:50.377644Z",
     "iopub.status.idle": "2024-10-03T02:38:50.382175Z",
     "shell.execute_reply": "2024-10-03T02:38:50.381443Z"
    },
    "papermill": {
     "duration": 0.015339,
     "end_time": "2024-10-03T02:38:50.384152",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.368813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "\n",
    "# Define the mapping for each level\n",
    "level_mapping = {\n",
    "    'L1/L2': 'l1_l2',\n",
    "    'L2/L3': 'l2_l3',\n",
    "    'L3/L4': 'l3_l4',\n",
    "    'L4/L5': 'l4_l5',\n",
    "    'L5/S1': 'l5_s1'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd8678cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.401856Z",
     "iopub.status.busy": "2024-10-03T02:38:50.401552Z",
     "iopub.status.idle": "2024-10-03T02:38:50.406250Z",
     "shell.execute_reply": "2024-10-03T02:38:50.405410Z"
    },
    "papermill": {
     "duration": 0.015571,
     "end_time": "2024-10-03T02:38:50.408207",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.392636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b54df390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.425419Z",
     "iopub.status.busy": "2024-10-03T02:38:50.425097Z",
     "iopub.status.idle": "2024-10-03T02:38:50.443949Z",
     "shell.execute_reply": "2024-10-03T02:38:50.443048Z"
    },
    "papermill": {
     "duration": 0.029916,
     "end_time": "2024-10-03T02:38:50.446259",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.416343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L4/L5</th>\n",
       "      <th>L3/L4</th>\n",
       "      <th>L2/L3</th>\n",
       "      <th>L1/L2</th>\n",
       "      <th>L5/S1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>st_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44036939</th>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L4_L5.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L3_L4.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L2_L3.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L1_L2.npy</td>\n",
       "      <td>/kaggle/working/sagittalT2/44036939/L5_S1.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  L4/L5  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L4_L5.npy   \n",
       "\n",
       "                                                  L3/L4  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L3_L4.npy   \n",
       "\n",
       "                                                  L2/L3  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L2_L3.npy   \n",
       "\n",
       "                                                  L1/L2  \\\n",
       "st_id                                                     \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L1_L2.npy   \n",
       "\n",
       "                                                  L5/S1  \n",
       "st_id                                                    \n",
       "44036939  /kaggle/working/sagittalT2/44036939/L5_S1.npy  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to CSV file\n",
    "csv_file_path = DATA_fromStage1 + '/sagittalT2/dataset_metadata.csv'\n",
    "# Read the CSV file\n",
    "dataset_metadata = pd.read_csv(csv_file_path)\n",
    "dataset_metadata.rename(columns={'Unnamed: 0': 'st_id'}, inplace=True)\n",
    "dataset_metadata.set_index('st_id', inplace=True)\n",
    "\n",
    "\n",
    "# # Print the number of columns and rows in the DataFrame\n",
    "# num_rows = dataset_metadata.shape[0]\n",
    "# print(f\"columns: {dataset_metadata.columns}\")\n",
    "# print(f\"Number of rows: {num_rows}\")\n",
    "\n",
    "# # print(dataset_metadata.head())\n",
    "# # Stack the 2nd to 6th columns into a single column\n",
    "# stacked_df = dataset_metadata.stack(dropna=False).reset_index(level=1)\n",
    "# stacked_df.columns = ['Level', 'fn']\n",
    "'''# stacked_df = stacked_df.reset_index(drop=True)\n",
    "print(stacked_df)\n",
    "\n",
    "print(\"----------- test index 0 -------------\")\n",
    "st_id = stacked_df.index[0]\n",
    "row_idx = stacked_df.iloc[0]\n",
    "print(st_id)\n",
    "print(row_idx['Level'])\n",
    "print(row_idx['fn'])\n",
    "print(\"----------- test index 1 -------------\")\n",
    "st_id = stacked_df.index[1]\n",
    "row_idx = stacked_df.iloc[1]\n",
    "print(st_id)\n",
    "print(row_idx['Level'])\n",
    "print(row_idx['fn'])'''\n",
    "\n",
    "dataset_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d6352c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.464758Z",
     "iopub.status.busy": "2024-10-03T02:38:50.463980Z",
     "iopub.status.idle": "2024-10-03T02:38:50.471227Z",
     "shell.execute_reply": "2024-10-03T02:38:50.470433Z"
    },
    "papermill": {
     "duration": 0.01823,
     "end_time": "2024-10-03T02:38:50.473114",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.454884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# one npy file example\\nprint(\"--------------------- SagittalT2 samples -----------\")\\nexample_npy_fn = dataset_metadata[\\'L4/L5\\'][0]\\nexample_npy_fn = example_npy_fn.split(\\'/\\')\\n# Load the .npy file\\nexample_npy = np.load(os.path.join(DATA_fromStage1, *(example_npy_fn[-3:])))\\n# Print the structure of the data\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\n# Show the 15 slices one by one\\nfor i in range(15):\\n    plt.imshow(example_npy[i], cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n\\nprint(\"--------------------- SagittalT1 samples -----------\")\\nexample_npy = np.load(os.path.join(DATA_fromStage1, \\'sagittalT1\\', *(example_npy_fn[-2:])))\\n# Print the structure of the data\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\n# Show the 15 slices one by one\\nfor i in range(15):\\n    plt.imshow(example_npy[i], cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n\\nprint(\"--------------------- AxialT2 samples ----------\")\\n# Load the .npy file\\nexample_npy = np.load(os.path.join(DATA_fromStage1, \\'axialT2\\', *(example_npy_fn[-2:])))\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\nfor i in range(6):\\n    img = example_npy[i]\\n    plt.imshow(img, cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# one npy file example\n",
    "print(\"--------------------- SagittalT2 samples -----------\")\n",
    "example_npy_fn = dataset_metadata['L4/L5'][0]\n",
    "example_npy_fn = example_npy_fn.split('/')\n",
    "# Load the .npy file\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, *(example_npy_fn[-3:])))\n",
    "# Print the structure of the data\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "# Show the 15 slices one by one\n",
    "for i in range(15):\n",
    "    plt.imshow(example_npy[i], cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"--------------------- SagittalT1 samples -----------\")\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, 'sagittalT1', *(example_npy_fn[-2:])))\n",
    "# Print the structure of the data\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "# Show the 15 slices one by one\n",
    "for i in range(15):\n",
    "    plt.imshow(example_npy[i], cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"--------------------- AxialT2 samples ----------\")\n",
    "# Load the .npy file\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, 'axialT2', *(example_npy_fn[-2:])))\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "for i in range(6):\n",
    "    img = example_npy[i]\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398b216",
   "metadata": {
    "papermill": {
     "duration": 0.008169,
     "end_time": "2024-10-03T02:38:50.489580",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.481411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "661cd512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.508076Z",
     "iopub.status.busy": "2024-10-03T02:38:50.507675Z",
     "iopub.status.idle": "2024-10-03T02:38:50.527337Z",
     "shell.execute_reply": "2024-10-03T02:38:50.526496Z"
    },
    "papermill": {
     "duration": 0.03119,
     "end_time": "2024-10-03T02:38:50.529164",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.497974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RSNA24TestDataset(Dataset):\n",
    "    def __init__(self, df_fn, Slice_len_Sag=15, Slice_len_Axi=4, transform=None, trainsform_axis=None):\n",
    "        self.df_fn = df_fn\n",
    "        self.transform = transform\n",
    "        self.trainsform_axis = trainsform_axis\n",
    "        self.Slice_len_Sag = Slice_len_Sag\n",
    "        self.Slice_len_Axi = Slice_len_Axi\n",
    "        # Select all rows where the 'Name' column has the value 'Alice'\n",
    "    def __len__(self):\n",
    "        return len(self.df_fn)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        st_id = self.df_fn.index[idx]\n",
    "        row_idx = self.df_fn.iloc[idx]\n",
    "        levels = ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']\n",
    "        filenames = [row_idx[level] for level in levels]\n",
    "        \n",
    "        npy_sagT2_list = []\n",
    "        npy_sagT1_list = []\n",
    "        npy_AxiT2_list = []\n",
    "    \n",
    "        for filename in filenames:\n",
    "            path_split = filename.split('/')\n",
    "            \n",
    "            # Saggital T2 ------------  Load the .npy file\n",
    "            npy_sagT2_path = os.path.join(DATA_fromStage1, path_split[3], path_split[4], path_split[5])\n",
    "            npy_sagT2 = np.load(npy_sagT2_path).astype(np.float32)\n",
    "            current_length = npy_sagT2.shape[0]\n",
    "            if current_length > self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT2 = npy_sagT2[indices, :, :]\n",
    "            elif current_length < self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT2 = npy_sagT2[indices, :, :]\n",
    "            npy_sagT2_list.append(npy_sagT2)\n",
    "            # Saggital T1 ------------  Load the .npy file\n",
    "            npy_sagT1_path = os.path.join(DATA_fromStage1, \"sagittalT1\", path_split[4], path_split[5])\n",
    "            npy_sagT1 = np.load(npy_sagT1_path).astype(np.float32)\n",
    "            current_length = npy_sagT1.shape[0]\n",
    "            if current_length > self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT1 = npy_sagT1[indices, :, :]\n",
    "            elif current_length < self.Slice_len_Sag:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "                npy_sagT1 = npy_sagT1[indices, :, :]\n",
    "            npy_sagT1_list.append(npy_sagT1)\n",
    "            # Axial T2 ------------ Load the .npy file\n",
    "            npy_AxiT2_path = os.path.join(DATA_fromStage1 , \"axialT2\", path_split[4], path_split[5])\n",
    "            npy_AxiT2 = np.load(npy_AxiT2_path).astype(np.float32)\n",
    "            current_length = npy_AxiT2.shape[0]\n",
    "            if current_length > self.Slice_len_Axi:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Axi, dtype=int)\n",
    "                npy_AxiT2 = npy_AxiT2[indices, :, :]\n",
    "            elif current_length < self.Slice_len_Axi:\n",
    "                indices = np.linspace(0, current_length - 1, self.Slice_len_Axi, dtype=int)\n",
    "                npy_AxiT2 = npy_AxiT2[indices, :, :]\n",
    "            npy_AxiT2_list.append(npy_AxiT2)\n",
    "            \n",
    "        # Transpose and transform the data\n",
    "        npy_sagT1_list = [np.transpose(npy, (1, 2, 0)) for npy in npy_sagT1_list]\n",
    "        npy_sagT2_list = [np.transpose(npy, (1, 2, 0)) for npy in npy_sagT2_list]\n",
    "        npy_AxiT2_list = [np.transpose(npy, (1, 2, 0)) for npy in npy_AxiT2_list]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            npy_sagT1_list = [self.transform(image=npy)['image'] for npy in npy_sagT1_list]\n",
    "            npy_sagT2_list = [self.transform(image=npy)['image'] for npy in npy_sagT2_list]\n",
    "            npy_AxiT2_list = [self.trainsform_axis(image=npy)['image'] for npy in npy_AxiT2_list]\n",
    "\n",
    "        # Transpose back to the original format\n",
    "        npy_sagT1_list = [np.transpose(npy, (2, 0, 1)) for npy in npy_sagT1_list]\n",
    "        npy_sagT2_list = [np.transpose(npy, (2, 0, 1)) for npy in npy_sagT2_list]\n",
    "        npy_AxiT2_list = [np.transpose(npy, (2, 0, 1)) for npy in npy_AxiT2_list]\n",
    "\n",
    "        return st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7367234d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.546784Z",
     "iopub.status.busy": "2024-10-03T02:38:50.546496Z",
     "iopub.status.idle": "2024-10-03T02:38:50.551469Z",
     "shell.execute_reply": "2024-10-03T02:38:50.550750Z"
    },
    "papermill": {
     "duration": 0.015902,
     "end_time": "2024-10-03T02:38:50.553348",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.537446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms_test_Sag = A.Compose([\n",
    "    A.Resize(84, 160),\n",
    "    A.Normalize(mean=0.5, std=0.5)\n",
    "])\n",
    "\n",
    "transforms_test = A.Compose([\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "    A.Normalize(mean=0.5, std=0.5)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aaa2cad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.571152Z",
     "iopub.status.busy": "2024-10-03T02:38:50.570888Z",
     "iopub.status.idle": "2024-10-03T02:38:50.575370Z",
     "shell.execute_reply": "2024-10-03T02:38:50.574593Z"
    },
    "papermill": {
     "duration": 0.015565,
     "end_time": "2024-10-03T02:38:50.577135",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.561570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = RSNA24TestDataset(dataset_metadata, transform=transforms_test_Sag, trainsform_axis=transforms_test)\n",
    "test_dl = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=1, \n",
    "    shuffle=False,\n",
    "    num_workers=N_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a6927ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.594645Z",
     "iopub.status.busy": "2024-10-03T02:38:50.594401Z",
     "iopub.status.idle": "2024-10-03T02:38:50.600450Z",
     "shell.execute_reply": "2024-10-03T02:38:50.599657Z"
    },
    "papermill": {
     "duration": 0.016912,
     "end_time": "2024-10-03T02:38:50.602380",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.585468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from collections import Counter\\n\\nsagT2_slicenum = []\\nAxiT2_slicenum = []\\n\\nprint(test_dl.__len__())\\n\\n# Iterate through the data loader and append slice numbers\\nfor idx, (st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels) in enumerate(test_dl):\\n    for npy_sagT2 in npy_sagT2_list:\\n        sagT2_slicenum.append(npy_sagT2.shape)\\n        assert not torch.isnan(npy_sagT2).any(), \"NaN values found in npy_sagT2\"\\n    \\n    for npy_AxiT2 in npy_AxiT2_list:\\n        AxiT2_slicenum.append(npy_AxiT2.shape)\\n        assert not torch.isnan(npy_AxiT2).any(), \"NaN values found in npy_AxiT2\"\\n    \\n    print(f\"Batch {idx + 1}: Levels - {levels}\")\\n\\n# Count the occurrences of each unique value in the lists\\nsagT2_counts = Counter(sagT2_slicenum)\\nAxiT2_counts = Counter(AxiT2_slicenum)\\n\\nprint(\"Occurrences of each unique value in sagT2_slicenum:\")\\nfor value, count in sagT2_counts.items():\\n    print(f\"Value: {value}, Count: {count}\")\\n\\nprint(\"Occurrences of each unique value in AxiT2_slicenum:\")\\nfor value, count in AxiT2_counts.items():\\n    print(f\"Value: {value}, Count: {count}\")'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from collections import Counter\n",
    "\n",
    "sagT2_slicenum = []\n",
    "AxiT2_slicenum = []\n",
    "\n",
    "print(test_dl.__len__())\n",
    "\n",
    "# Iterate through the data loader and append slice numbers\n",
    "for idx, (st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels) in enumerate(test_dl):\n",
    "    for npy_sagT2 in npy_sagT2_list:\n",
    "        sagT2_slicenum.append(npy_sagT2.shape)\n",
    "        assert not torch.isnan(npy_sagT2).any(), \"NaN values found in npy_sagT2\"\n",
    "    \n",
    "    for npy_AxiT2 in npy_AxiT2_list:\n",
    "        AxiT2_slicenum.append(npy_AxiT2.shape)\n",
    "        assert not torch.isnan(npy_AxiT2).any(), \"NaN values found in npy_AxiT2\"\n",
    "    \n",
    "    print(f\"Batch {idx + 1}: Levels - {levels}\")\n",
    "\n",
    "# Count the occurrences of each unique value in the lists\n",
    "sagT2_counts = Counter(sagT2_slicenum)\n",
    "AxiT2_counts = Counter(AxiT2_slicenum)\n",
    "\n",
    "print(\"Occurrences of each unique value in sagT2_slicenum:\")\n",
    "for value, count in sagT2_counts.items():\n",
    "    print(f\"Value: {value}, Count: {count}\")\n",
    "\n",
    "print(\"Occurrences of each unique value in AxiT2_slicenum:\")\n",
    "for value, count in AxiT2_counts.items():\n",
    "    print(f\"Value: {value}, Count: {count}\")'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125b3a22",
   "metadata": {
    "papermill": {
     "duration": 0.008605,
     "end_time": "2024-10-03T02:38:50.619462",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.610857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aa450f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.637687Z",
     "iopub.status.busy": "2024-10-03T02:38:50.637397Z",
     "iopub.status.idle": "2024-10-03T02:38:50.650782Z",
     "shell.execute_reply": "2024-10-03T02:38:50.649918Z"
    },
    "papermill": {
     "duration": 0.02469,
     "end_time": "2024-10-03T02:38:50.652664",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.627974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LevelHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LevelHead, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class RSNA24Model_Hybrid(nn.Module):\n",
    "    def __init__(self, model_name_sag, model_name_axi, in_chans_sag, in_chans_axi, num_classes, level_names):\n",
    "        super(RSNA24Model_Hybrid, self).__init__()\n",
    "        self.model_sag = timm.create_model(model_name_sag, in_chans=in_chans_sag, global_pool='avg'\n",
    "                                           , pretrained=False, features_only=False)\n",
    "        self.model_axi = timm.create_model(model_name_axi, in_chans=in_chans_axi, global_pool='avg'\n",
    "                                           , pretrained=False, features_only=False)\n",
    "        \n",
    "        # Replace the last layer with an identity layer\n",
    "        if hasattr(self.model_sag, 'classifier'):\n",
    "            self.model_sag.classifier = nn.Identity()\n",
    "        elif hasattr(self.model_sag, 'fc'):\n",
    "            self.model_sag.fc = nn.Identity()\n",
    "        \n",
    "        if hasattr(self.model_axi, 'classifier'):\n",
    "            self.model_axi.classifier = nn.Identity()\n",
    "        elif hasattr(self.model_axi, 'fc'):\n",
    "            self.model_axi.fc = nn.Identity()\n",
    "        \n",
    "        # Get the output feature sizes\n",
    "        with torch.no_grad():\n",
    "            sample_input_sag = torch.randn(1, in_chans_sag, 84, 160)\n",
    "            sample_input_axi = torch.randn(1, in_chans_axi, 224, 224)\n",
    "            output_sag = self.model_sag(sample_input_sag)\n",
    "            output_axi = self.model_axi(sample_input_axi)\n",
    "        \n",
    "        # Define the final fully connected layers for each task\n",
    "        self.fc_heads = nn.ModuleDict({\n",
    "            level: LevelHead(output_sag.shape[1] + output_axi.shape[1], num_classes) for level in level_names\n",
    "        })\n",
    "        \n",
    "    def forward(self, x_sag, x_axi, level):\n",
    "        x_sag = self.model_sag(x_sag)\n",
    "        x_axi = self.model_axi(x_axi)\n",
    "        x = torch.cat((x_sag, x_axi), dim=1)\n",
    "        x = self.fc_heads[level[0]](x) # the input level is a array associated with batch size\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df3983",
   "metadata": {
    "papermill": {
     "duration": 0.008377,
     "end_time": "2024-10-03T02:38:50.669420",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.661043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d10dfe51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.687759Z",
     "iopub.status.busy": "2024-10-03T02:38:50.687110Z",
     "iopub.status.idle": "2024-10-03T02:38:50.699316Z",
     "shell.execute_reply": "2024-10-03T02:38:50.698635Z"
    },
    "papermill": {
     "duration": 0.023395,
     "end_time": "2024-10-03T02:38:50.701219",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.677824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CKPT_PATHS = glob.glob('/kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-*.pt')\n",
    "CKPT_PATHS = sorted(CKPT_PATHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b64d3287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:38:50.719613Z",
     "iopub.status.busy": "2024-10-03T02:38:50.719328Z",
     "iopub.status.idle": "2024-10-03T02:39:00.206324Z",
     "shell.execute_reply": "2024-10-03T02:39:00.205471Z"
    },
    "papermill": {
     "duration": 9.498519,
     "end_time": "2024-10-03T02:39:00.208456",
     "exception": false,
     "start_time": "2024-10-03T02:38:50.709937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-0.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-1.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-2.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-3.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-4.pt...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(models)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure device is set correctly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = []\n",
    "for i, cp in enumerate(CKPT_PATHS):\n",
    "    print(f'loading {cp}...')\n",
    "    model = RSNA24Model_Hybrid(model_name_sag, model_name_axi,\n",
    "                               in_chans_sag, in_chans_axi, \n",
    "                               num_classes=N_CLASSES, level_names=level_mapping.keys())\n",
    "    model.load_state_dict(torch.load(cp, map_location=device))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "'''print(models)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c4fd5",
   "metadata": {
    "papermill": {
     "duration": 0.008661,
     "end_time": "2024-10-03T02:39:00.226471",
     "exception": false,
     "start_time": "2024-10-03T02:39:00.217810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cae9ca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:39:00.245856Z",
     "iopub.status.busy": "2024-10-03T02:39:00.245521Z",
     "iopub.status.idle": "2024-10-03T02:39:01.872507Z",
     "shell.execute_reply": "2024-10-03T02:39:01.871466Z"
    },
    "papermill": {
     "duration": 1.640227,
     "end_time": "2024-10-03T02:39:01.875645",
     "exception": false,
     "start_time": "2024-10-03T02:39:00.235418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "y_preds = []\n",
    "row_names = []\n",
    "\n",
    "seq_cond = [1, 3, 2, 4, 0]\n",
    "with tqdm(test_dl, leave=True) as pbar:\n",
    "    with torch.no_grad():\n",
    "        for idx, (st_id, npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels) in enumerate(pbar):\n",
    "            pred_per_study = np.zeros((25, 3))\n",
    "            index = 0  # Initialize the index counter\n",
    "            for npy_sagT1, npy_sagT2, npy_AxiT2, level in zip(npy_sagT1_list, npy_sagT2_list, npy_AxiT2_list, levels):        \n",
    "                pred_per_study_level = np.zeros((5, 3))  \n",
    "                npy_sagT1 = npy_sagT1.to(device)\n",
    "                npy_sagT2 = npy_sagT2.to(device)\n",
    "                npy_AxiT2 = npy_AxiT2.to(device)\n",
    "                with torch.cuda.amp.autocast(): \n",
    "                    for m in models:    \n",
    "                        y = m(torch.cat((npy_sagT1, npy_sagT2), axis=1), npy_AxiT2, level)[0]\n",
    "                        for col in range(N_LABELS):\n",
    "                            pred = y[col*3:col*3+3]\n",
    "                            y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "                            pred_per_study_level[col] += y_pred / len(models)\n",
    "                    # pred_per_study_level (5, 3)\n",
    "                for i in range(5):\n",
    "                    pred_per_study[index + i*5, :] = pred_per_study_level[seq_cond[i], :]\n",
    "                index += 1  # Increment the index for the next iteration\n",
    "\n",
    "            # Add row names following the new sequence\n",
    "            for cond_idx in seq_cond:\n",
    "                cond = CONDITIONS[cond_idx]\n",
    "                for i in range(5):\n",
    "                    row_name = f\"{str(st_id.item())}_{cond}_{level_mapping[''.join(levels[i])]}\"\n",
    "                    row_names.append(row_name)\n",
    "            \n",
    "            y_preds.append(pred_per_study)\n",
    "        \n",
    "y_preds = np.concatenate(y_preds, axis=0)\n",
    "                    \n",
    "print(len(row_names))\n",
    "print(len(y_preds))\n",
    "\n",
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5940ceca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:39:01.896171Z",
     "iopub.status.busy": "2024-10-03T02:39:01.895872Z",
     "iopub.status.idle": "2024-10-03T02:39:01.910078Z",
     "shell.execute_reply": "2024-10-03T02:39:01.908878Z"
    },
    "papermill": {
     "duration": 0.02686,
     "end_time": "2024-10-03T02:39:01.912120",
     "exception": false,
     "start_time": "2024-10-03T02:39:01.885260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             row_id  normal_mild  moderate  \\\n",
      "0    44036939_left_neural_foraminal_narrowing_l1_l2     0.333333  0.333333   \n",
      "1    44036939_left_neural_foraminal_narrowing_l2_l3     0.333333  0.333333   \n",
      "2    44036939_left_neural_foraminal_narrowing_l3_l4     0.333333  0.333333   \n",
      "3    44036939_left_neural_foraminal_narrowing_l4_l5     0.333333  0.333333   \n",
      "4    44036939_left_neural_foraminal_narrowing_l5_s1     0.333333  0.333333   \n",
      "5         44036939_left_subarticular_stenosis_l1_l2     0.333333  0.333333   \n",
      "6         44036939_left_subarticular_stenosis_l2_l3     0.333333  0.333333   \n",
      "7         44036939_left_subarticular_stenosis_l3_l4     0.333333  0.333333   \n",
      "8         44036939_left_subarticular_stenosis_l4_l5     0.333333  0.333333   \n",
      "9         44036939_left_subarticular_stenosis_l5_s1     0.333333  0.333333   \n",
      "10  44036939_right_neural_foraminal_narrowing_l1_l2     0.333333  0.333333   \n",
      "11  44036939_right_neural_foraminal_narrowing_l2_l3     0.333333  0.333333   \n",
      "12  44036939_right_neural_foraminal_narrowing_l3_l4     0.333333  0.333333   \n",
      "13  44036939_right_neural_foraminal_narrowing_l4_l5     0.333333  0.333333   \n",
      "14  44036939_right_neural_foraminal_narrowing_l5_s1     0.333333  0.333333   \n",
      "15       44036939_right_subarticular_stenosis_l1_l2     0.333333  0.333333   \n",
      "16       44036939_right_subarticular_stenosis_l2_l3     0.333333  0.333333   \n",
      "17       44036939_right_subarticular_stenosis_l3_l4     0.333333  0.333333   \n",
      "18       44036939_right_subarticular_stenosis_l4_l5     0.333333  0.333333   \n",
      "19       44036939_right_subarticular_stenosis_l5_s1     0.333333  0.333333   \n",
      "20             44036939_spinal_canal_stenosis_l1_l2     0.333333  0.333333   \n",
      "21             44036939_spinal_canal_stenosis_l2_l3     0.333333  0.333333   \n",
      "22             44036939_spinal_canal_stenosis_l3_l4     0.333333  0.333333   \n",
      "23             44036939_spinal_canal_stenosis_l4_l5     0.333333  0.333333   \n",
      "24             44036939_spinal_canal_stenosis_l5_s1     0.333333  0.333333   \n",
      "\n",
      "      severe  \n",
      "0   0.333333  \n",
      "1   0.333333  \n",
      "2   0.333333  \n",
      "3   0.333333  \n",
      "4   0.333333  \n",
      "5   0.333333  \n",
      "6   0.333333  \n",
      "7   0.333333  \n",
      "8   0.333333  \n",
      "9   0.333333  \n",
      "10  0.333333  \n",
      "11  0.333333  \n",
      "12  0.333333  \n",
      "13  0.333333  \n",
      "14  0.333333  \n",
      "15  0.333333  \n",
      "16  0.333333  \n",
      "17  0.333333  \n",
      "18  0.333333  \n",
      "19  0.333333  \n",
      "20  0.333333  \n",
      "21  0.333333  \n",
      "22  0.333333  \n",
      "23  0.333333  \n",
      "24  0.333333  \n"
     ]
    }
   ],
   "source": [
    "sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')\n",
    "LABELS = list(sample_sub.columns[1:])\n",
    "print(sample_sub.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f426083",
   "metadata": {
    "papermill": {
     "duration": 0.009486,
     "end_time": "2024-10-03T02:39:01.931772",
     "exception": false,
     "start_time": "2024-10-03T02:39:01.922286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1229b421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:39:01.951942Z",
     "iopub.status.busy": "2024-10-03T02:39:01.951617Z",
     "iopub.status.idle": "2024-10-03T02:39:01.964365Z",
     "shell.execute_reply": "2024-10-03T02:39:01.963472Z"
    },
    "papermill": {
     "duration": 0.024973,
     "end_time": "2024-10-03T02:39:01.966316",
     "exception": false,
     "start_time": "2024-10-03T02:39:01.941343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             row_id  normal_mild  moderate  \\\n",
      "0    44036939_left_neural_foraminal_narrowing_l1_l2     0.613067  0.248803   \n",
      "1    44036939_left_neural_foraminal_narrowing_l2_l3     0.583494  0.310914   \n",
      "2    44036939_left_neural_foraminal_narrowing_l3_l4     0.387378  0.416965   \n",
      "3    44036939_left_neural_foraminal_narrowing_l4_l5     0.274075  0.437970   \n",
      "4    44036939_left_neural_foraminal_narrowing_l5_s1     0.292484  0.365523   \n",
      "5         44036939_left_subarticular_stenosis_l1_l2     0.521431  0.269302   \n",
      "6         44036939_left_subarticular_stenosis_l2_l3     0.409832  0.316396   \n",
      "7         44036939_left_subarticular_stenosis_l3_l4     0.269406  0.320883   \n",
      "8         44036939_left_subarticular_stenosis_l4_l5     0.161473  0.305819   \n",
      "9         44036939_left_subarticular_stenosis_l5_s1     0.372218  0.323221   \n",
      "10  44036939_right_neural_foraminal_narrowing_l1_l2     0.597046  0.234189   \n",
      "11  44036939_right_neural_foraminal_narrowing_l2_l3     0.614038  0.295967   \n",
      "12  44036939_right_neural_foraminal_narrowing_l3_l4     0.364929  0.437056   \n",
      "13  44036939_right_neural_foraminal_narrowing_l4_l5     0.270597  0.429432   \n",
      "14  44036939_right_neural_foraminal_narrowing_l5_s1     0.304412  0.353359   \n",
      "15       44036939_right_subarticular_stenosis_l1_l2     0.518742  0.290086   \n",
      "16       44036939_right_subarticular_stenosis_l2_l3     0.436897  0.332067   \n",
      "17       44036939_right_subarticular_stenosis_l3_l4     0.254744  0.338275   \n",
      "18       44036939_right_subarticular_stenosis_l4_l5     0.162199  0.289142   \n",
      "19       44036939_right_subarticular_stenosis_l5_s1     0.340472  0.314072   \n",
      "20             44036939_spinal_canal_stenosis_l1_l2     0.566128  0.240752   \n",
      "21             44036939_spinal_canal_stenosis_l2_l3     0.542258  0.253573   \n",
      "22             44036939_spinal_canal_stenosis_l3_l4     0.355958  0.283290   \n",
      "23             44036939_spinal_canal_stenosis_l4_l5     0.318709  0.217259   \n",
      "24             44036939_spinal_canal_stenosis_l5_s1     0.744945  0.132495   \n",
      "\n",
      "      severe  \n",
      "0   0.138130  \n",
      "1   0.105593  \n",
      "2   0.195657  \n",
      "3   0.287955  \n",
      "4   0.341993  \n",
      "5   0.209267  \n",
      "6   0.273771  \n",
      "7   0.409712  \n",
      "8   0.532707  \n",
      "9   0.304561  \n",
      "10  0.168765  \n",
      "11  0.089995  \n",
      "12  0.198016  \n",
      "13  0.299971  \n",
      "14  0.342229  \n",
      "15  0.191172  \n",
      "16  0.231037  \n",
      "17  0.406981  \n",
      "18  0.548659  \n",
      "19  0.345456  \n",
      "20  0.193120  \n",
      "21  0.204169  \n",
      "22  0.360752  \n",
      "23  0.464032  \n",
      "24  0.122561  \n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['row_id'] = row_names\n",
    "sub[LABELS] = y_preds\n",
    "print(sub.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93b831d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T02:39:01.987158Z",
     "iopub.status.busy": "2024-10-03T02:39:01.986583Z",
     "iopub.status.idle": "2024-10-03T02:39:01.994680Z",
     "shell.execute_reply": "2024-10-03T02:39:01.993882Z"
    },
    "papermill": {
     "duration": 0.020362,
     "end_time": "2024-10-03T02:39:01.996521",
     "exception": false,
     "start_time": "2024-10-03T02:39:01.976159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pd.read_csv('submission.csv').head()\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.to_csv('submission.csv', index=False)\n",
    "'''pd.read_csv('submission.csv').head()'''\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "datasetId": 5471909,
     "sourceId": 9529005,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 198313435,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199001269,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199192833,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.217658,
   "end_time": "2024-10-03T02:39:03.428033",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-03T02:38:21.210375",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
