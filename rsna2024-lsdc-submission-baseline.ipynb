{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e31e70",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.007934,
     "end_time": "2024-10-02T02:57:56.714589",
     "exception": false,
     "start_time": "2024-10-02T02:57:56.706655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adopted from https://www.kaggle.com/code/yxyyxy/rsna2024-training-baseline-2nd-stage/edit\n",
    "\n",
    "# RSNA2024 LSDC Submission Baseline\n",
    "\n",
    "This notebook will Let the model infer and make a submission.\n",
    "\n",
    "### My other Notebooks\n",
    "- [RSNA2024 LSDC Making Dataset](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-making-dataset) \n",
    "- [RSNA2024 LSDC Training Baseline](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-training-baseline) \n",
    "- [RSNA2024 LSDC Submission Baseline](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline) <- you're reading now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dbda7d",
   "metadata": {
    "papermill": {
     "duration": 0.007256,
     "end_time": "2024-10-02T02:57:56.729471",
     "exception": false,
     "start_time": "2024-10-02T02:57:56.722215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9ae6f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:57:56.745380Z",
     "iopub.status.busy": "2024-10-02T02:57:56.744989Z",
     "iopub.status.idle": "2024-10-02T02:58:17.880552Z",
     "shell.execute_reply": "2024-10-02T02:58:17.879300Z"
    },
    "papermill": {
     "duration": 21.146244,
     "end_time": "2024-10-02T02:58:17.883098",
     "exception": false,
     "start_time": "2024-10-02T02:57:56.736854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using path: /kaggle/input/2d-segmentation-of-sagittal-lumbar-spine-mri/simple_unet.pth\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\r\n",
      "  warnings.warn(msg)\r\n",
      "Using path: /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\r\n",
      "Using base path: /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images\r\n",
      "Processing studies: 100%|█████████████████████████| 1/1 [00:08<00:00,  8.09s/it]\r\n",
      "Pipeline completed successfully!\r\n",
      "Processing studies: 100%|█████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\r\n",
      "Axial dataset generation completed successfully!\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/input/script-deepspine-custom-dataset/main.py \\\n",
    "'/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv' \\\n",
    "'/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv' \\\n",
    "'/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images' \\\n",
    "'/kaggle/input/2d-segmentation-of-sagittal-lumbar-spine-mri/simple_unet.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30675f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:17.902678Z",
     "iopub.status.busy": "2024-10-02T02:58:17.902310Z",
     "iopub.status.idle": "2024-10-02T02:58:22.872971Z",
     "shell.execute_reply": "2024-10-02T02:58:22.872219Z"
    },
    "papermill": {
     "duration": 4.982364,
     "end_time": "2024-10-02T02:58:22.875278",
     "exception": false,
     "start_time": "2024-10-02T02:58:17.892914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import timm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb7c58b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:22.893428Z",
     "iopub.status.busy": "2024-10-02T02:58:22.892851Z",
     "iopub.status.idle": "2024-10-02T02:58:22.897100Z",
     "shell.execute_reply": "2024-10-02T02:58:22.896293Z"
    },
    "papermill": {
     "duration": 0.015317,
     "end_time": "2024-10-02T02:58:22.899074",
     "exception": false,
     "start_time": "2024-10-02T02:58:22.883757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "\n",
    "# Define the directory path\n",
    "DATA_fromStage1 = '/kaggle/working'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99581a6",
   "metadata": {
    "papermill": {
     "duration": 0.008457,
     "end_time": "2024-10-02T02:58:22.915752",
     "exception": false,
     "start_time": "2024-10-02T02:58:22.907295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79070dc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:22.933755Z",
     "iopub.status.busy": "2024-10-02T02:58:22.933484Z",
     "iopub.status.idle": "2024-10-02T02:58:23.003373Z",
     "shell.execute_reply": "2024-10-02T02:58:23.002439Z"
    },
    "papermill": {
     "duration": 0.08167,
     "end_time": "2024-10-02T02:58:23.005345",
     "exception": false,
     "start_time": "2024-10-02T02:58:22.923675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = f'/kaggle/input/rsna2024-lsdc-training-baseline/rsna24-results'\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "N_WORKERS = os.cpu_count()\n",
    "USE_AMP = True\n",
    "SEED = 1\n",
    "\n",
    "IMG_SIZE = [225, 225]\n",
    "N_LABELS = 5\n",
    "N_CLASSES = 3 * N_LABELS\n",
    "\n",
    "model_name_sag = 'efficientnet_b0'\n",
    "model_name_axi = 'resnet34'\n",
    "# resnet34\n",
    "in_chans_sag = 30\n",
    "in_chans_axi = 4\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30cd156c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.023077Z",
     "iopub.status.busy": "2024-10-02T02:58:23.022454Z",
     "iopub.status.idle": "2024-10-02T02:58:23.029168Z",
     "shell.execute_reply": "2024-10-02T02:58:23.028422Z"
    },
    "papermill": {
     "duration": 0.017396,
     "end_time": "2024-10-02T02:58:23.030989",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.013593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b1c639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.048500Z",
     "iopub.status.busy": "2024-10-02T02:58:23.048227Z",
     "iopub.status.idle": "2024-10-02T02:58:23.052641Z",
     "shell.execute_reply": "2024-10-02T02:58:23.051840Z"
    },
    "papermill": {
     "duration": 0.015387,
     "end_time": "2024-10-02T02:58:23.054492",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.039105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "\n",
    "# Define the mapping for each level\n",
    "level_mapping = {\n",
    "    'L1/L2': 'l1_l2',\n",
    "    'L2/L3': 'l2_l3',\n",
    "    'L3/L4': 'l3_l4',\n",
    "    'L4/L5': 'l4_l5',\n",
    "    'L5/S1': 'l5_s1'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a195fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.072034Z",
     "iopub.status.busy": "2024-10-02T02:58:23.071583Z",
     "iopub.status.idle": "2024-10-02T02:58:23.076255Z",
     "shell.execute_reply": "2024-10-02T02:58:23.075451Z"
    },
    "papermill": {
     "duration": 0.015733,
     "end_time": "2024-10-02T02:58:23.078373",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.062640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab31643a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.095752Z",
     "iopub.status.busy": "2024-10-02T02:58:23.095495Z",
     "iopub.status.idle": "2024-10-02T02:58:23.114744Z",
     "shell.execute_reply": "2024-10-02T02:58:23.113684Z"
    },
    "papermill": {
     "duration": 0.030135,
     "end_time": "2024-10-02T02:58:23.116559",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.086424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: Index(['L4/L5', 'L3/L4', 'L2/L3', 'L1/L2', 'L5/S1'], dtype='object')\n",
      "Number of rows: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/4021975579.py:15: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  stacked_df = dataset_metadata.stack(dropna=False).reset_index(level=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# stacked_df = stacked_df.reset_index(drop=True)\\nprint(stacked_df)\\n\\nprint(\"----------- test index 0 -------------\")\\nst_id = stacked_df.index[0]\\nrow_idx = stacked_df.iloc[0]\\nprint(st_id)\\nprint(row_idx[\\'Level\\'])\\nprint(row_idx[\\'fn\\'])\\nprint(\"----------- test index 1 -------------\")\\nst_id = stacked_df.index[1]\\nrow_idx = stacked_df.iloc[1]\\nprint(st_id)\\nprint(row_idx[\\'Level\\'])\\nprint(row_idx[\\'fn\\'])'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to CSV file\n",
    "csv_file_path = DATA_fromStage1 + '/sagittalT2/dataset_metadata.csv'\n",
    "# Read the CSV file\n",
    "dataset_metadata = pd.read_csv(csv_file_path)\n",
    "dataset_metadata.rename(columns={'Unnamed: 0': 'st_id'}, inplace=True)\n",
    "dataset_metadata.set_index('st_id', inplace=True)\n",
    "\n",
    "# Print the number of columns and rows in the DataFrame\n",
    "num_rows = dataset_metadata.shape[0]\n",
    "print(f\"columns: {dataset_metadata.columns}\")\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "\n",
    "# print(dataset_metadata.head())\n",
    "# Stack the 2nd to 6th columns into a single column\n",
    "stacked_df = dataset_metadata.stack(dropna=False).reset_index(level=1)\n",
    "stacked_df.columns = ['Level', 'fn']\n",
    "'''# stacked_df = stacked_df.reset_index(drop=True)\n",
    "print(stacked_df)\n",
    "\n",
    "print(\"----------- test index 0 -------------\")\n",
    "st_id = stacked_df.index[0]\n",
    "row_idx = stacked_df.iloc[0]\n",
    "print(st_id)\n",
    "print(row_idx['Level'])\n",
    "print(row_idx['fn'])\n",
    "print(\"----------- test index 1 -------------\")\n",
    "st_id = stacked_df.index[1]\n",
    "row_idx = stacked_df.iloc[1]\n",
    "print(st_id)\n",
    "print(row_idx['Level'])\n",
    "print(row_idx['fn'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06bd1398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.134625Z",
     "iopub.status.busy": "2024-10-02T02:58:23.134356Z",
     "iopub.status.idle": "2024-10-02T02:58:23.141328Z",
     "shell.execute_reply": "2024-10-02T02:58:23.140560Z"
    },
    "papermill": {
     "duration": 0.01838,
     "end_time": "2024-10-02T02:58:23.143326",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.124946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# one npy file example\\nprint(\"--------------------- SagittalT2 samples -----------\")\\nexample_npy_fn = dataset_metadata[\\'L4/L5\\'][0]\\nexample_npy_fn = example_npy_fn.split(\\'/\\')\\n# Load the .npy file\\nexample_npy = np.load(os.path.join(DATA_fromStage1, *(example_npy_fn[-3:])))\\n# Print the structure of the data\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\n# Show the 15 slices one by one\\nfor i in range(15):\\n    plt.imshow(example_npy[i], cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n\\nprint(\"--------------------- SagittalT1 samples -----------\")\\nexample_npy = np.load(os.path.join(DATA_fromStage1, \\'sagittalT1\\', *(example_npy_fn[-2:])))\\n# Print the structure of the data\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\n# Show the 15 slices one by one\\nfor i in range(15):\\n    plt.imshow(example_npy[i], cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n\\nprint(\"--------------------- AxialT2 samples ----------\")\\n# Load the .npy file\\nexample_npy = np.load(os.path.join(DATA_fromStage1, \\'axialT2\\', *(example_npy_fn[-2:])))\\nprint(f\"Shape of the data: {example_npy.shape}\")\\nprint(f\"Data type: {example_npy.dtype}\")\\nfor i in range(6):\\n    img = example_npy[i]\\n    plt.imshow(img, cmap=\\'gray\\')\\n    plt.title(f\\'Slice {i+1}\\')\\n    plt.axis(\\'off\\')\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# one npy file example\n",
    "print(\"--------------------- SagittalT2 samples -----------\")\n",
    "example_npy_fn = dataset_metadata['L4/L5'][0]\n",
    "example_npy_fn = example_npy_fn.split('/')\n",
    "# Load the .npy file\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, *(example_npy_fn[-3:])))\n",
    "# Print the structure of the data\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "# Show the 15 slices one by one\n",
    "for i in range(15):\n",
    "    plt.imshow(example_npy[i], cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"--------------------- SagittalT1 samples -----------\")\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, 'sagittalT1', *(example_npy_fn[-2:])))\n",
    "# Print the structure of the data\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "# Show the 15 slices one by one\n",
    "for i in range(15):\n",
    "    plt.imshow(example_npy[i], cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"--------------------- AxialT2 samples ----------\")\n",
    "# Load the .npy file\n",
    "example_npy = np.load(os.path.join(DATA_fromStage1, 'axialT2', *(example_npy_fn[-2:])))\n",
    "print(f\"Shape of the data: {example_npy.shape}\")\n",
    "print(f\"Data type: {example_npy.dtype}\")\n",
    "for i in range(6):\n",
    "    img = example_npy[i]\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f'Slice {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb85ae9",
   "metadata": {
    "papermill": {
     "duration": 0.008367,
     "end_time": "2024-10-02T02:58:23.160861",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.152494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42ddc312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.179560Z",
     "iopub.status.busy": "2024-10-02T02:58:23.179239Z",
     "iopub.status.idle": "2024-10-02T02:58:23.198580Z",
     "shell.execute_reply": "2024-10-02T02:58:23.197640Z"
    },
    "papermill": {
     "duration": 0.03126,
     "end_time": "2024-10-02T02:58:23.200715",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.169455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RSNA24TestDataset(Dataset):\n",
    "    def __init__(self, df_fn, Slice_len_Sag=15, Slice_len_Axi=4, transform=None, trainsform_axis=None):\n",
    "        self.df_fn = df_fn\n",
    "        self.transform = transform\n",
    "        self.trainsform_axis = trainsform_axis\n",
    "        self.Slice_len_Sag = Slice_len_Sag\n",
    "        self.Slice_len_Axi = Slice_len_Axi\n",
    "        # Select all rows where the 'Name' column has the value 'Alice'\n",
    "    def __len__(self):\n",
    "        return len(self.df_fn)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        st_id = stacked_df.index[idx]\n",
    "        row_idx = stacked_df.iloc[idx]\n",
    "        level = (row_idx['Level'])\n",
    "        filename = row_idx['fn']\n",
    "        \n",
    "        path_split = filename.split('/')\n",
    "        # Saggital T2 ------------  Load the .npy file\n",
    "        npy_sagT2_path = os.path.join(DATA_fromStage1, path_split[3], path_split[4], path_split[5])\n",
    "        npy_sagT2 = np.load(npy_sagT2_path).astype(np.float32)\n",
    "        current_length = npy_sagT2.shape[0]\n",
    "        if current_length > self.Slice_len_Sag:\n",
    "            indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "            npy_sagT2 = npy_sagT2[indices, :, :]\n",
    "        elif current_length < self.Slice_len_Sag:\n",
    "            indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "            npy_sagT2 = npy_sagT2[indices, :, :]\n",
    "\n",
    "        # Saggital T1 ------------  Load the .npy file\n",
    "        npy_sagT1_path = os.path.join(DATA_fromStage1, \"sagittalT1\", path_split[4], path_split[5])\n",
    "        npy_sagT1 = np.load(npy_sagT1_path).astype(np.float32)\n",
    "        current_length = npy_sagT1.shape[0]\n",
    "        if current_length > self.Slice_len_Sag:\n",
    "            indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "            npy_sagT1 = npy_sagT1[indices, :, :]\n",
    "        elif current_length < self.Slice_len_Sag:\n",
    "            indices = np.linspace(0, current_length - 1, self.Slice_len_Sag, dtype=int)\n",
    "            npy_sagT1 = npy_sagT1[indices, :, :]\n",
    "\n",
    "        # Axial T2 ------------ Load the .npy file\n",
    "        npy_AxiT2_path = os.path.join(DATA_fromStage1 , \"axialT2\", path_split[4], path_split[5])\n",
    "        npy_AxiT2 = np.load(npy_AxiT2_path).astype(np.float32)\n",
    "        current_length = npy_AxiT2.shape[0]\n",
    "        if current_length > self.Slice_len_Axi:\n",
    "            indices = np.linspace(0, current_length - 1, self.Slice_len_Axi, dtype=int)\n",
    "            npy_AxiT2 = npy_AxiT2[indices, :, :]\n",
    "        elif current_length < self.Slice_len_Axi:\n",
    "            indices = np.linspace(0, current_length - 1, self.Slice_len_Axi, dtype=int)\n",
    "            npy_AxiT2 = npy_AxiT2[indices, :, :]\n",
    "\n",
    "        #  npy_sagT2 and npy_AxiT2 are in the format [channels, height, width]        \n",
    "        npy_sagT1 = np.transpose(npy_sagT1, (1, 2, 0))  # Transpose to [height, width, channels]\n",
    "        npy_sagT2 = np.transpose(npy_sagT2, (1, 2, 0))  # Transpose to [height, width, channels]\n",
    "        npy_AxiT2 = np.transpose(npy_AxiT2, (1, 2, 0))  # Transpose to [height, width, channels]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            npy_sagT1 = self.transform(image=npy_sagT1)['image']\n",
    "            npy_sagT2 = self.transform(image=npy_sagT2)['image']\n",
    "            npy_AxiT2 = self.trainsform_axis(image=npy_AxiT2)['image']\n",
    "\n",
    "        # transpose back to the original format\n",
    "        npy_sagT1 = np.transpose(npy_sagT1, (2, 0, 1))\n",
    "        npy_sagT2 = np.transpose(npy_sagT2, (2, 0, 1))  # Transpose back to [channels, height, width]\n",
    "        npy_AxiT2 = np.transpose(npy_AxiT2, (2, 0, 1))  # Transpose back to [channels, height, width]\n",
    "\n",
    "        return st_id, npy_sagT1, npy_sagT2, npy_AxiT2, level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d8ddf27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.221234Z",
     "iopub.status.busy": "2024-10-02T02:58:23.220951Z",
     "iopub.status.idle": "2024-10-02T02:58:23.226804Z",
     "shell.execute_reply": "2024-10-02T02:58:23.225863Z"
    },
    "papermill": {
     "duration": 0.018598,
     "end_time": "2024-10-02T02:58:23.229102",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.210504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms_test_Sag = A.Compose([\n",
    "    A.Resize(84, 160),\n",
    "    A.Normalize(mean=0.5, std=0.5)\n",
    "])\n",
    "\n",
    "transforms_test = A.Compose([\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "    A.Normalize(mean=0.5, std=0.5)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b12256b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.250151Z",
     "iopub.status.busy": "2024-10-02T02:58:23.249560Z",
     "iopub.status.idle": "2024-10-02T02:58:23.254494Z",
     "shell.execute_reply": "2024-10-02T02:58:23.253614Z"
    },
    "papermill": {
     "duration": 0.017925,
     "end_time": "2024-10-02T02:58:23.256644",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.238719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = RSNA24TestDataset(stacked_df, transform=transforms_test_Sag, trainsform_axis=transforms_test)\n",
    "test_dl = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=1, \n",
    "    shuffle=False,\n",
    "    num_workers=N_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca570bfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.275820Z",
     "iopub.status.busy": "2024-10-02T02:58:23.275568Z",
     "iopub.status.idle": "2024-10-02T02:58:23.590819Z",
     "shell.execute_reply": "2024-10-02T02:58:23.589775Z"
    },
    "papermill": {
     "duration": 0.32707,
     "end_time": "2024-10-02T02:58:23.592865",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.265795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['L4/L5']\n",
      "['L3/L4']\n",
      "['L2/L3']\n",
      "['L1/L2']\n",
      "['L5/S1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(\"Occurrences of each unique value in sagT2_slicenum:\")\\nfor value, count in sagT2_counts.items():\\n    print(f\"Value: {value}, Count: {count}\")\\n\\nprint(\"Occurrences of each unique value in AxiT2_slicenum:\")\\nfor value, count in AxiT2_counts.items():\\n    print(f\"Value: {value}, Count: {count}\")'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "sagT2_slicenum = []\n",
    "AxiT2_slicenum = []\n",
    "\n",
    "print(test_dl.__len__())\n",
    "\n",
    "# Iterate through the data loader and append slice numbers\n",
    "for idx, (st_id, npy_sagT1, npy_sagT2, npy_AxiT2, level) in enumerate(test_dl):\n",
    "    sagT2_slicenum.append(npy_sagT2.shape)\n",
    "    AxiT2_slicenum.append(npy_AxiT2.shape)\n",
    "    assert not torch.isnan(npy_sagT2).any(), \"NaN values found in npy_sagT2\"\n",
    "    assert not torch.isnan(npy_AxiT2).any(), \"NaN values found in npy_AxiT2\"\n",
    "    print(level)\n",
    "\n",
    "# Count the occurrences of each unique value in the lists\n",
    "sagT2_counts = Counter(sagT2_slicenum)\n",
    "AxiT2_counts = Counter(AxiT2_slicenum)\n",
    "\n",
    "'''print(\"Occurrences of each unique value in sagT2_slicenum:\")\n",
    "for value, count in sagT2_counts.items():\n",
    "    print(f\"Value: {value}, Count: {count}\")\n",
    "\n",
    "print(\"Occurrences of each unique value in AxiT2_slicenum:\")\n",
    "for value, count in AxiT2_counts.items():\n",
    "    print(f\"Value: {value}, Count: {count}\")'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5dfbb",
   "metadata": {
    "papermill": {
     "duration": 0.009115,
     "end_time": "2024-10-02T02:58:23.611079",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.601964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9012d63a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.631073Z",
     "iopub.status.busy": "2024-10-02T02:58:23.630226Z",
     "iopub.status.idle": "2024-10-02T02:58:23.644371Z",
     "shell.execute_reply": "2024-10-02T02:58:23.643690Z"
    },
    "papermill": {
     "duration": 0.026462,
     "end_time": "2024-10-02T02:58:23.646385",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.619923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LevelHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LevelHead, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class RSNA24Model_Hybrid(nn.Module):\n",
    "    def __init__(self, model_name_sag, model_name_axi, in_chans_sag, in_chans_axi, num_classes, level_names):\n",
    "        super(RSNA24Model_Hybrid, self).__init__()\n",
    "        self.model_sag = timm.create_model(model_name_sag, in_chans=in_chans_sag, global_pool='avg'\n",
    "                                           , pretrained=False, features_only=False)\n",
    "        self.model_axi = timm.create_model(model_name_axi, in_chans=in_chans_axi, global_pool='avg'\n",
    "                                           , pretrained=False, features_only=False)\n",
    "        \n",
    "        # Replace the last layer with an identity layer\n",
    "        if hasattr(self.model_sag, 'classifier'):\n",
    "            self.model_sag.classifier = nn.Identity()\n",
    "        elif hasattr(self.model_sag, 'fc'):\n",
    "            self.model_sag.fc = nn.Identity()\n",
    "        \n",
    "        if hasattr(self.model_axi, 'classifier'):\n",
    "            self.model_axi.classifier = nn.Identity()\n",
    "        elif hasattr(self.model_axi, 'fc'):\n",
    "            self.model_axi.fc = nn.Identity()\n",
    "        \n",
    "        # Get the output feature sizes\n",
    "        with torch.no_grad():\n",
    "            sample_input_sag = torch.randn(1, in_chans_sag, 84, 160)\n",
    "            sample_input_axi = torch.randn(1, in_chans_axi, 224, 224)\n",
    "            output_sag = self.model_sag(sample_input_sag)\n",
    "            output_axi = self.model_axi(sample_input_axi)\n",
    "        \n",
    "        # Define the final fully connected layers for each task\n",
    "        self.fc_heads = nn.ModuleDict({\n",
    "            level: LevelHead(output_sag.shape[1] + output_axi.shape[1], num_classes) for level in level_names\n",
    "        })\n",
    "        \n",
    "    def forward(self, x_sag, x_axi, level):\n",
    "        x_sag = self.model_sag(x_sag)\n",
    "        x_axi = self.model_axi(x_axi)\n",
    "        x = torch.cat((x_sag, x_axi), dim=1)\n",
    "        x = self.fc_heads[level[0]](x) # the input level is a array associated with batch size\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b4858",
   "metadata": {
    "papermill": {
     "duration": 0.009043,
     "end_time": "2024-10-02T02:58:23.664913",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.655870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72ae69dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.684769Z",
     "iopub.status.busy": "2024-10-02T02:58:23.684471Z",
     "iopub.status.idle": "2024-10-02T02:58:23.693909Z",
     "shell.execute_reply": "2024-10-02T02:58:23.693159Z"
    },
    "papermill": {
     "duration": 0.021666,
     "end_time": "2024-10-02T02:58:23.695928",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.674262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "CKPT_PATHS = glob.glob('/kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-*.pt')\n",
    "CKPT_PATHS = sorted(CKPT_PATHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d98ff8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:23.715749Z",
     "iopub.status.busy": "2024-10-02T02:58:23.715478Z",
     "iopub.status.idle": "2024-10-02T02:58:33.066146Z",
     "shell.execute_reply": "2024-10-02T02:58:33.065204Z"
    },
    "papermill": {
     "duration": 9.363399,
     "end_time": "2024-10-02T02:58:33.068529",
     "exception": false,
     "start_time": "2024-10-02T02:58:23.705130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-0.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-1.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-2.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-3.pt...\n",
      "loading /kaggle/input/tpu-rsna2024-training-baseline-2nd-stage/rsna24-results/best_wll_model_fold-4.pt...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(models)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure device is set correctly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = []\n",
    "for i, cp in enumerate(CKPT_PATHS):\n",
    "    print(f'loading {cp}...')\n",
    "    model = RSNA24Model_Hybrid(model_name_sag, model_name_axi,\n",
    "                               in_chans_sag, in_chans_axi, \n",
    "                               num_classes=N_CLASSES, level_names=level_mapping.keys())\n",
    "    model.load_state_dict(torch.load(cp, map_location=device))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "'''print(models)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714d3c6",
   "metadata": {
    "papermill": {
     "duration": 0.009135,
     "end_time": "2024-10-02T02:58:33.087178",
     "exception": false,
     "start_time": "2024-10-02T02:58:33.078043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c27aaa46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:33.107537Z",
     "iopub.status.busy": "2024-10-02T02:58:33.106793Z",
     "iopub.status.idle": "2024-10-02T02:58:34.622448Z",
     "shell.execute_reply": "2024-10-02T02:58:34.621466Z"
    },
    "papermill": {
     "duration": 1.527895,
     "end_time": "2024-10-02T02:58:34.624482",
     "exception": false,
     "start_time": "2024-10-02T02:58:33.096587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(len(row_names))\\nprint(y_preds)\\nprint(y_preds.shape)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "y_preds = []\n",
    "row_names = []\n",
    "\n",
    "with tqdm(test_dl, leave=True) as pbar:\n",
    "    with torch.no_grad():\n",
    "        for idx, (st_id, npy_sagT1, npy_sagT2, npy_AxiT2, level) in enumerate(pbar):\n",
    "            npy_sagT1 = npy_sagT1.to(device)\n",
    "            npy_sagT2 = npy_sagT2.to(device)\n",
    "            npy_AxiT2 = npy_AxiT2.to(device)\n",
    "            pred_per_study = np.zeros((5, 3))  \n",
    "            with torch.cuda.amp.autocast(): \n",
    "                for m in models:    \n",
    "                    y = m(torch.cat((npy_sagT1, npy_sagT2), axis=1), npy_AxiT2, level)[0]\n",
    "                    for col in range(N_LABELS):\n",
    "                        pred = y[col*3:col*3+3]\n",
    "                        y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "                        pred_per_study[col] += y_pred / len(models)\n",
    "                y_preds.append(pred_per_study)\n",
    "\n",
    "            for cond in CONDITIONS:\n",
    "                row_name = f\"{str(st_id.item())}_{cond}_{level_mapping[''.join(level)]}\"\n",
    "                row_names.append(row_name)\n",
    "\n",
    "y_preds = np.concatenate(y_preds, axis=0)\n",
    "                    \n",
    "'''print(len(row_names))\n",
    "print(y_preds)\n",
    "print(y_preds.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98d8fc9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:34.646478Z",
     "iopub.status.busy": "2024-10-02T02:58:34.646145Z",
     "iopub.status.idle": "2024-10-02T02:58:34.655586Z",
     "shell.execute_reply": "2024-10-02T02:58:34.654755Z"
    },
    "papermill": {
     "duration": 0.022471,
     "end_time": "2024-10-02T02:58:34.657403",
     "exception": false,
     "start_time": "2024-10-02T02:58:34.634932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normal_mild', 'moderate', 'severe']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')\n",
    "LABELS = list(sample_sub.columns[1:])\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cbd91d",
   "metadata": {
    "papermill": {
     "duration": 0.009788,
     "end_time": "2024-10-02T02:58:34.677315",
     "exception": false,
     "start_time": "2024-10-02T02:58:34.667527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eef499b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:34.698671Z",
     "iopub.status.busy": "2024-10-02T02:58:34.698360Z",
     "iopub.status.idle": "2024-10-02T02:58:34.708986Z",
     "shell.execute_reply": "2024-10-02T02:58:34.707959Z"
    },
    "papermill": {
     "duration": 0.023509,
     "end_time": "2024-10-02T02:58:34.710958",
     "exception": false,
     "start_time": "2024-10-02T02:58:34.687449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub.head(25)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['row_id'] = row_names\n",
    "sub[LABELS] = y_preds\n",
    "'''sub.head(25)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d5f8b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:58:34.732528Z",
     "iopub.status.busy": "2024-10-02T02:58:34.732034Z",
     "iopub.status.idle": "2024-10-02T02:58:34.739936Z",
     "shell.execute_reply": "2024-10-02T02:58:34.739176Z"
    },
    "papermill": {
     "duration": 0.020777,
     "end_time": "2024-10-02T02:58:34.741803",
     "exception": false,
     "start_time": "2024-10-02T02:58:34.721026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pd.read_csv('submission.csv').head()\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.to_csv('submission.csv', index=False)\n",
    "'''pd.read_csv('submission.csv').head()'''"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "sourceId": 198313435,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199001269,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199046231,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.192021,
   "end_time": "2024-10-02T02:58:36.072872",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-02T02:57:53.880851",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
